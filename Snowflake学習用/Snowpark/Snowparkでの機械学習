#パッケージのトグルを開き、検索でsnowflake-ml-python,snowflake-snowpark-pythonのインポート
# 左記にenvironment.ymlができる(ここに上記記載される)
#使用する元データ(CUSTOMER_DATA_180)にはID, AGE,GENDER,ANNUAL_INCOME(年収), CHURN列(解約なら1,0)がある。AGE,GENDER,ANNUAL_INCOMEを使い予測
#XGブーストによる機械学習

## Sessionの確立
from snoflake.snowpark.cntext import get_active_session
session = get_active_session()

df = session.table("CUSTOMER_DATA_1808")
df
type(df) # snowflakeであることがわかる

## 学習データとテストデータにわける
train_df, test_df = df.random_split([0.6, 0.2], seed = 2) #seed=2：乱数の初期化値を指定して、毎回同じ分割結果にするため。
print(train_df.count(), test_df.count())


## インポート

#Snowflake Machine Learning（Snowpark ML） で 欠損値（NaN/null）の補完処理（imputation） を行うためのモジュール
from snowflake.ml.modeling.impute import SimpleImputer
#特徴量の**標準化（平均0、標準偏差1）**を行う前処理クラスで
from snowflake.ml.modeling.preprocessing import StanderdScaler, OrdinalEnocoder
# XGboostの使用
from snowflake.ml.modeling.xgboost import XGBClassifier
# 複数の前処理や学習処理を一連のステップとしてまとめる
from snowflake.ml.modeling pipeline import Pipeline


## 数値データ（age, annual_income）に欠損値補完を行うための SimpleImputer を作成
numeric_imputer = SimpleImputer(
    strategy="median",  # 欠損値の補完方法として「中央値（median）」を使用
    input_cols=["age", "annual_income"],  # 補完対象の列（欠損がある可能性のある数値列）
    output_cols=["age", "annual_income"],  # 補完後に出力される列名（上書きする形）
    passthrough_cols=["gender", "churn"],  # 補完しないが、そのままパイプラインに通す列
    drop_input_cols=True  # 入力列を削除（output_cols と同じなら上書きの意味）
)

# カテゴリ変数（文字列）の欠損値を補完するための SimpleImputer を作成
categorical_imputer = SimpleImputer(
    strategy="most_frequent",  # 欠損値を「最も頻繁に出現する値（最頻値）」で補完
    input_cols=["gender"],     # 補完の対象となる列（ここでは gender）
    output_cols=["gender"],    # 補完後の出力列（同名なので上書き）
    passthrough_cols=["age", "anuual_income", "churn"],  # 補完せずにそのまま通す列（後続処理のために保持）
    drop_input_cols=True       # 元の gender 列を削除し、output_cols で置き換える
)

## encoding(genderがM,Fで入ってるため1,0に置き換える)

## scaler age income（機械学習で使う前に数値のスケール（大きさ）を揃える処理）

## モデリングを実施

