{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e427e8f2-ad78-4022-b6f1-c1d53f274512",
   "metadata": {},
   "source": [
    "### 模擬試験でのポイント\n",
    "\n",
    "\n",
    "[**IAM**]<br>\n",
    "- IAMポリシーは、**IAMユーザーやIAMロールに対する権限範囲を規定する記述文書**です。これによって権限範囲を詳細に設定することができます。しかしながら**IAMポリシーによって定められた権限範囲をリソースに付与する際はIAMロールが必要**となります。\n",
    "- IAMユーザーは**ユーザーアカウントの権限設定**に利用します。**リソースに対するアクセス権限設定にはIAMロール**を利用\n",
    "- IAMロールをEC2インスタンスに設定してDynamoDBへの読取を許可することなども可能\n",
    "- IAMロールを使用してS3バケットへの特定のアクセスを必要とするEC2インスタンスにアクセス権限を付与することができます。\n",
    "- **バケットポリシーでもアクセス制御ができますが、特定のユーザー単位**でのアクセス制御を主としており、特定IPのEC2インスタンスからのアクセス制御にはIAMロールの方が最適\n",
    "- **S3においてIAMポリシーはアクセス許可範囲を特定のバケットに限定することが可能**\n",
    "- これらIAMによる設定で「S3 APIのアクセスを制限することが必要」なケースに対応可能\n",
    "- (注意点)またGlacierはS3のストレージクラスのタイプとなっているため、バケットポリシーでS3バケットのデータをGlacierにバックアップするアクセスを制限することはできません。\n",
    "[**Amazon EC2**]<br>\n",
    "- backupを取得するには、**EC2インスタンスを停止し、各EC2インスタンスボリュームのスナップショットを個別に作成する。** スナップショットが完了したら、EC2インスタンスを起動し、関連するすべてのボリュームが再マウントされていることを確認する\n",
    "- EC2インスタンス間を通信するためにはプライベートIPアドレスを指定することで実施できます。\n",
    "- EC2インスタンス間を通信するために、Elastic IPは必要ありません。\n",
    "\n",
    "[**カスタマーゲートウェイ**]<br>\n",
    "- カスタマーゲートウェイに静的ルートテーブルを構成して、パブリックおよびプライベートの AWSネットワークに接続するための仮想インターフェイスへのルートを設定することで、VPC接続を構成\n",
    "- Amazon VPC VPN 接続では、データセンター (またはネットワーク) を Amazon VPC 仮想プライベートクラウド (VPC) にリンクします。カスタマーゲートウェイは、その接続の作業者側のアンカーです。\n",
    "- (注意点) Route53はVPN接続には利用できません。\n",
    "\n",
    "[**Direct Connect**]<br>\n",
    "- AWSとオンプレミス環境間の専用線接続サービスです。Direct Connectを構成した上で、IPsecを追加することができます\n",
    "\n",
    "[**Egress Only-インターネットゲートウェイ**]\n",
    "- IPv6 経由で プライベートサブネット からインターネットへの送信を可能にするゲートウェイ\n",
    "\n",
    "[**AWS Organizations**]<br>\n",
    "- 複数アカウントをメンバーアカウントとしてグループ化した**OUに対して、サービスコントロールポリシー(SCP)を設定する**ことで、複数アカウント内で設定で切るAWSリソースのアクション権限範囲を管理することができます。\n",
    "- SCP内で許可した範囲においてIAMポリシーによるアクセス権限付与が実行できるアカウント\n",
    "  - (イメージ)IAM(EC2・ECSへの許可)、SCP(EC2、RDS・ECSの許可)=EC2・ECSの許可のみ\n",
    "  - **ユーザーに対してアクセス許可権限を付与しません。**\n",
    "\n",
    "[**AWS Storage Gateway**]<br>\n",
    "- Amazon S3バケットとオンプレミスストレージを接続して、バックアップを取得したり、ストレージ容量を拡張したりすることができるハイブリッドクラウド機能を提供\n",
    "- オンプレミスアプリケーションによる AWS クラウドストレージのシームレス（違和感なく統合されている）な使用を可能にするハイブリッドストレージサービス。バックアップ、アーカイブ、災害対策、クラウドデータ処理、ストレージの階層化、および移行を行うことができます。\n",
    "- **保管型ボリューム**を使用すると、プライマリデータをローカルに保存する一方で、そのデータを非同期に AWS にバックアップします。\n",
    "- 上記は「Amazon Elastic Block Store (Amazon EBS) スナップショットとして Amazon S3 に非同期でバックアップ」される\n",
    "- **キャッシュ型ボリューム**を使用することで、頻繁にアクセスされるデータはローカルのストレージゲートウェイに保持しながら、Amazon S3 をプライマリデータストレージとして使用\n",
    "- つまり保管型が「AWSクラウドにストレージを拡張するケース」で用いられる\n",
    "\n",
    "[**Amazon FSx for Windows File Server**]<br>\n",
    "- AWS Managed Microsoft AD ディレクトリを利用した認証を設定することが必須となります。したがって、AWS Managed Microsoft AD ディレクトリを構成した上で、このADを認証基盤に利用して Amazon FSx for Windows File Serverを構成し、このファイルシステムをWindowsインスタンスにマウント\n",
    "\n",
    "[**S3**]<br>\n",
    "- バケットポリシーは**Amazon S3バケットのアクセス制御をバケット側で設定することができるポリシー**\n",
    "- Amazon S3バケットは**バケットポリシーの設定許可があり、かつ、パブリックブロックアクセスが無効化されている場合に、インターネットから誰でもオブジェクトデータにアクセスできることが可能なストレージ**\n",
    "- また、バケットポリシーの設定により、インターネットからのバケットへの**s3:GetObject を設定する必要があります。**\n",
    "- CloudFrontにおいて署名付きURLおよび署名付きCookiesを利用することで、Amazon S3の事前署名付きURLと同じような効果を達成することができます。これらはAmazon S3の事前署名付き URLと同じような機能を提供します。\n",
    "- S3バケットのオブジェクトロックのコンプライアンスモードでは、指定した保持期間中にS3バケット内のオブジェクトに対してデータ変更や削除ができなくなります。\n",
    "- コンプライアンスモードでは、AWS アカウント の root ユーザーを含め、ユーザーが、保護されたオブジェクトのバージョンを上書きまたは削除することはできません\n",
    "- ガバナンスモードでは、必要に応じて一部のユーザーにリテンション設定の変更、またはオブジェクトの削除を許可することができます。\n",
    "- (注意点)**オブジェクトロックの有効化は、S3バケットを作成する際にしか実施できません。**\n",
    "- (注意点)**バケットポリシーにWAFを設定することができない。WAFはCloudFrontに設定する必要があります。**\n",
    "- 「データ量を抑えるために保存後に1ヶ月以上すぎた場合は対象ビデオデータを削除すること」の要件をかなえるには**S3 Standard IAにビデオを保存してライフサイクルポリシーで1か月後に削除する。**\n",
    "- Amazon S3バケットの**GetObject権限を付与するAssumeRoleを実施するIAMロールを作成して、特定のユーザーにのみ権限を委譲することで、クロスアカウントアクセスを可能にします。**\n",
    "- **AsumeRoleを利用することで IAM ロールに設定された権限を移譲することができます。**\n",
    "- ドキュメント管理システムでは頻繁にドキュメントの変更が発生するため、**Amazon S3バケットのバージョニングを有効化して、適切なバージョン管理を実行**\n",
    "- **Amazon S3 Transfer Acceleration** を使用すると、クライアントと S3 バケットの間で、長距離にわたるファイル転送を高速、簡単、安全に行えるようになります。\n",
    "- **各オブジェクトの現在の日付をプレフィックスとして付与することで読み取りと書き取りのトラフィック量が増大すると予想されているアプリでもパフォーマンスを最大化できる**\n",
    "  \n",
    "\n",
    "\n",
    "[**AWS Glue**]<br>\n",
    "- AWS Glue は抽出、変換、ロード (ETL) を行う完全マネージド型のサービスで分析用データの準備とロードを簡単にします。これを利用して、S3からデータを抽出し、ターゲットスキーマに自動的に一致するようにデータを変換することが可能です。AWSに保存されたデータを指定するだけで AWS Glue によるデータ検索が行われ、テーブル定義やスキーマなどの関連するメタデータが AWS Glue データカタログに保存されます。\n",
    "\n",
    "[**インターネットゲートウェイとルーティング**]<br>\n",
    "- パブリックサブネットとしてインターネットからのアクセスを許可するためにはインターネットゲートウェイが必要です。設定としては、このEC2インスタンスにはインターネットから自由にアクセスするWEBサイトを構築する予定であるため、インターネットゲートウェイに対して0.0.0.0/0でフルオープンを設定することが求められる(**Destination：0.0.0.0/0  - >Target：インターネットゲートウェイ**)\n",
    "- 「**VPC内に設置したEC2インスタンスに対してインターネットからアクセスできない場合**」は以下の要因が考えられる\n",
    "  - インターネットゲートウェイがサブネットに設定されていない。\n",
    "  - ネットワークACLの設定でインターネットアクセス許可が設定されていない。\n",
    "  - セキュリティグループの設定でインターネットアクセス許可が設定されていない。\n",
    "  - パブリックIPアドレスが付与されていない。\n",
    "\n",
    "[**AWS Certificate Manager**]<br>\n",
    "- AWS Nitro Enclavesを利用したインスタンスを利用することで、EC2インスタンスにAWS Certificate Manager上のSSL証明書を設定できるようになりました。その際は、特定のIAMロールに証明書を関連付けて、AWS Nitro Enclavesを利用したインスタンスに対して、そのIAMロールを設定することが必要となります。\n",
    "- 既存のSSL証明書をAWS Certificate ManagerにインポートしてAWS上で利用することができます。そして、ACMからSSL証明書を実施するHTTPSリスナーを持つALBを設定することで、クライアントからALBへの通信を暗号化することが可能となります。ALBでは、暗号化用の HTTPS リスナーを作成して、ACMのSSL証明書を設定することで、暗号化通信を実施します。この機能によって、ロードバランサーと SSL あるいは TLS セッションを開始したクライアント間のトラフィックを暗号化できます。\n",
    "- AWS Certificate ManagerのSSL証明書はAmazon CloudFrontやELBに設定することが必要\n",
    "- (注意点)ALBにACM証明書を設定する際はTSLリスナーではなく、 HTTPS リスナーを利用\n",
    "\n",
    "[**Auto Scalingグループ**] <br>\n",
    "- Auto Scalingでは、スケーリングがうまく実行されずに24時間以上たった場合は、自動的にAuto Scaling処理が停止するようになっています。\n",
    "- インスタンスの起動を繰り返し、24時間失敗し続けるとAmazon側で停止する可能性がある\n",
    "- インスタンスの状態がImpairedになると、数分間リカバリーされるかチェックする\n",
    "- AutoScalingを一時的に停止しないでインスタンスを停止すると新規インスタンスが起動してしまう\n",
    "- ステップスケーリングポリシーは、CloudWatchメトリクスから得られる値（CPU使用率やSQSキューサイズなど）の閾値を超えて発せられるアラームに対して、値ベースでスケーリングアクションを個別設定できる機能\n",
    "- 現在のスケーリング設定では短期間にスケールアウトとスケールインを繰り返しており、問題となっています。この状況を改善するために必要となるスケーリング設定は・・\n",
    "  - **Auto Scalingグループのクールダウンタイム値を最適化する。**\n",
    "  - **Auto Scalingのスケールアウト時のポリシーをステップスケーリングポリシーにすることで、インスタンス増減をより詳細に制御する。**\n",
    "- **ターミネーションポリシーはスケールイン時のインスタンスを終了させる方法を定義するポリシー**\n",
    "- AutoScalingによって新規インスタンスが起動されましたが、新規インスタンス数の増加によるパフォーマンス向上効果が発揮されるまで遅いことが問題・・・その場合は「**AutoScalingのステップスケーリングポリシーによってウォームアップ条件を設定する。**」ことで改善\n",
    "  - これまでのスケーリングでは、単純にCPU使用率上がったら沢山インスタンスを追加してしまうといった実際のビジネスにフィットしないケースがありました。そこで、50%なら1台追加、60%なら2台追加、70%なら3台追加といった具合に、閾値を超えてアラームから報告される値によってスケールする台数を指定\n",
    "- スケジュールされたスケーリングでは、独自のスケーリングスケジュールを設定できます。これは負荷が高まる期間がわかっている際に利用\n",
    "\n",
    "[**Amazon CloudWatch**]<br>\n",
    "- AWSのリソース（EC2、RDS、Lambdaなど）の監視や、カスタムメトリクスの収集・アラート設定を行うサービスです。CloudWatchを使ってシステムの状態を監視し、**Auto Scalingのトリガーとして利用することができます。**\n",
    "- Auto Scalingグループを作成した後、CloudWatchアラームを設定して、スケーリングのトリガーとして使用できます。\n",
    "- **CPU使用率とディスクの読み取りメトリクスを組み合わせたCloudWatch複合アラームを作成して、両方のメトリクスに応じた通知を設定なども可能**\n",
    "- **CPU使用率が7０％以上に増加した場合にスケーリングするためには、ステップスケーリングポリシーではなく、ターゲット追跡スケーリングポリシーを設定**します。ステップスケーリングポリシーは複数段階の閾値を設定して、負荷上昇に応じて徐々にインスタンス数を増加させる際に利用するスケーリングポリシーです。１つの値を閾値に設定してスケーリングする際はターゲット追跡スケーリングポリシーを設定します。\n",
    "- CloudWatchを利用して複数のメトリクスを指定して複合アラームを設定します。Amazon EventBridgeはイベントに基づいてアクションを実施する機能であり、メトリクスに基づいたアクションは設定できません。たとえば、インスタンスの状態が保留中から実行中に変更されると、Amazon EC2 はイベントを生成します。\n",
    "\n",
    "[**Amazon EFS**]<br>\n",
    "- EFS のライフサイクル管理では「費用対効果の高いファイルストレージを自動的に管理します。有効にすると、ライフサイクル管理は 30 日間アクセスされなかったファイルを EFS IA ストレージクラスに自動的に移行します。ライフサイクル管理によってファイルが IA ストレージクラスに移動されると、**無期限にデータが残ります。削除をするわけではない**」\n",
    "- 「プライベートサブネット内のEC2インスタンスがEFSにアクセスする仕組みを構築しています。そのためにはAZにおいてアクセスポイントとなる設定が必要不可欠」・・・マウントターゲットを通してAmazon EFSのファイルシステムにアクセスする。仕組みが必要\n",
    "\n",
    "[**Amazon Aurora**]<br>\n",
    "- **Amazon Aurora MySQLデータベースはクラスター構成によって複数AZにまたがってボリュームを構成している** Amazon RDS MySQLデータベースに比較するとAZ障害には強い構成\n",
    "- しかしながら、Auroraデータベースはさらに展開時にマルチAZ配置を有効化して、Auroraレプリカを複数アベイラビリティゾーンに展開することが可能。そうすることで、プライマリDBが配置されているアベイラビリティゾーン（それを構成するデータセンター）に障害が発生した場合は、レプリカの１つをプライマリDBに昇格させることで、ダウンタイムを最小限にしてデータベース処理を継続させることができます。\n",
    "- **Aurora DB クラスターは、最大で 15個の Aurora レプリカを配置することができます。**\n",
    "- Aurora レプリカは、AWS リージョン内で DB クラスターが使用している複数のアベイラビリティーゾーン間に分散して配置できます。このレプリカは複数リージョンにも展開可能です。プライマリDBに障害が発生した場合は、１つのAurora レプリカをプライマリインスタンスに昇格することができます。\n",
    "- **プライマリインスタンスのみでもデータを3つのAZにかけて6個のレプリケーションを作成**\n",
    "- **プライマリインスタンス障害は10分未満でサービスが回復**\n",
    "- **1つ以上のAuroraレプリカがある場合には、復旧時間は120秒未満であり多くの場合60秒未満で復元**\n",
    "- **プライマリのインスタンスに障害が発生すると、Auroraレプリカがプライマリに昇格しフェイルオーバーします。 フェイルオーバーの時間に関しては、多くの場合は 60秒未満 とされています。数分程度という要件に対して特に問題なく機能することができます。**\n",
    "\n",
    "[**Amazon RDS DB**]<br>\n",
    "- Amazon RDS DBインスタンスはリードレプリカを追加して、アプリケーションの読み込み負荷を分散することができる、これは非同期レプリケーションです。\n",
    "- Optimesd Writeが利用できるMySQLバージョンに変更して、Optimesd Writeを適用して書き込み処理を高速化することも可能。Amazon RDSのOptimesd Writeは書き込み処理を最大50％向上できるRDSの機能\n",
    "- マルチAZ構成でRDSマスターともう一つのAZへはRDAスレーブを配置して同期レプリケーションによる自動フェイルオーバー機能も追加可能\n",
    "- Amazon RDSをAuroraサーバレス MySQLに変更することでピーク時にオートスケーリングはされますが、Auroraサーバレス はピーク以外の通常時においても一定のデータベース利用が発生しない、不規則なデータベース利用が発生する際に向いているDBタイプ\n",
    "- (注意点)クエリ処理には向いていますが、**ログ解析には向いていません**。\n",
    "- （注意点）**RDSのAuto Scalingはデータ容量を増加させるだけ**つまり読み取りリクエストの増加等には関係ない。読み取り専用のリードレプリカの用意や単純にコストが高くなりますが、より高性能なインスタンスタイプに変更してスケールアップすることも最適な対応\n",
    "- Optimized Readsインスタンスを利用することで、ホストサーバーに物理的に接続されたローカル NVMe ベースの SSD ブロックレベルストレージに MySQL が生成する一時テーブルを配置することによりクエリ処理が高速化されます。これにより、ソート、ハッシュ集計、高負荷結合、共通テーブル式 (CTE) を含むクエリなど、一時テーブルを利用する複雑なクエリ処理についても、最大 50% 高速化されます。\n",
    "- RDS Proxyは、アプリケーションとRDSデータベースの間の仲介役として機能します。RDS Proxyは、必要となるデータベースへのコネクションプールを確立および管理し、アプリケーションからのデータベース接続を少なく抑える機能\n",
    "- (注意点)暗号化がされていないDBインスタンスはスナップショットも含めて、**後から暗号化を設定することができません。** したがって、**最新のDBスナップショットを使用してDBインスタンスを再作成**して、その際に暗号化を有効化することが必要です。DBインスタンスの暗号化を有効化することで、スナップショットを含めてすべてのデータが暗号化されるようになります。\n",
    "- **ElastiCacheはRDSなどのデータベース処理の高速処理化などで利用するべき構成**\n",
    "\n",
    "\n",
    "[**AWS Systems Manager **]<br>\n",
    "- EC2インスタンスからAmazon RDS DBインスタンスにアクセスするために必要となるユーザー名とパスワードをセキュアに保存する目的のためにAWS Systems Manager パラメーターストアにパラメータを作成することができる\n",
    "- 主に右記のような使い方：パラメーターストアのパラメータに読み取りアクセスを許可するIAMポリシーを作成する。このIAMポリシーを設定したIAMロールをAmazon EC2インスタンスに割り当てる。EC2インスタンスがパラメーターを取得して、Amazon RDS DBインスタンス認証を実施する。\n",
    "\n",
    "\n",
    "[**Amazon EBS**]<br>\n",
    "- EBSのスループット最適化HDD\n",
    "  - 高いスループットを必要とするアクセス頻度の高いワークロード向けの低コストの HDD ボリューム.プロビジョンドIOPS SSDよりも低コストで実現  \n",
    "- EBSの汎用SSD\n",
    "   - 幅広いトランザクションワークロードに対応できる価格とパフォーマンスのバランスが取れた汎用 SSD ボリューム\n",
    "- EBSのプロビジョンドIOPS SSD\n",
    "   - イテンシーの影響が大きいトランザクションワークロード向けに設計された極めてパフォーマンスの高い SSD ボリューム。コストを度外視して、最も高いスループット性能を求められる際には正解\n",
    "- EBSのコールドHDD\n",
    "   - アクセス頻度の低いワークロード向けに設計された極めて低コストの HDD ボリューム\n",
    "- Amazon EBSは**Amazon S3 に格納するボリュームのポイントインタイムスナップショットを作成できます。** スナップショットを作成し、Amazon S3 へのコピーを完了すると 、1 つの AWS リージョンから別のリージョン、または同じリージョン内にスナップショットをコピーできます。その上で移動先リージョン内でEBSボリュームを複製することができます。\n",
    "- (補足)\n",
    " - RAID0は複数のディスクを１台のディスクのように扱うため、「読み書きを高速化する構成」\n",
    " - RAID1はボリュームの冗長性を高めるため、RAID1では２つのボリュームを同時にミラーリングする。つまり「EBSボリュームにおいて不具合や破損が発生してもデータ消失しないようにデータ保持する仕組みが必要」を実現する。スナップショットからの復元には、一定時間のシステム停止を要するため、ミラーリングに比較すると回復性が低い\n",
    " \n",
    "[**AWS Backup**]<br>\n",
    "- **様々なバックアップ処理を一元管理する仕組み**\n",
    "- **AWS BackupではAMIやスナップショットは別リージョンにコピーすることができます。**\n",
    "- 具体的には「AWS Backupを利用して、EBSのバックアップを取得して、対象EC2インスタンスのダウンに対して、新インスタンスを立上げてEBSボリュームを復元する。」ことで東京リージョンに障害が発生した場合に備えて、障害回復ソリューションを準備することが可能\n",
    "- こちらの対応も必須「AWS Backupを利用して、定期的にEC2インスタンスからAMIを取得して、別のリージョンにコピーするようにバックアッププランを作成する。」\n",
    "- \n",
    "[**DynamoDB**]<br>\n",
    "- DynamoDBをオンデマンドに変更することで、一時的な負荷に対してキャパシティをスケーリングして高負荷に対応することが可能<br>\n",
    "- (注意)*DynamoDBをマルチAZ構成で起動する機能はない*  \n",
    "- オートスケーリングを利用したり、Amazon SQSを構成した方がコスト最適に対応。ただし「DynamoDBのオンデマンドモードを選択すると、DynamoDB は、前に到達したトラフィックレベルまで拡張または縮小して、ワークロードを即座に受け入れることができるようにします。したがって、**このモードにはAuto Scalingは必要ありません**」\n",
    "- アプリケーションの構成を変更することなく、DynamoDBのパフォーマンス効率を向上させるには**Amazon DynamoDB Accelrator（DAX）を利用して、DynamoDBテーブルにキャッシュレイヤーを追加**して高速処理を実施\n",
    "- **DynamoDBストリームでは、テーブル内の項目が変更された際の変更内容をストリームして通知する機能**\n",
    "   - 24時間を経過するとデータ変更履歴は消去される\n",
    "   - \n",
    "- Lambda関数とAmazon EventBridgeと連携してDynamoDBをスケジュールに従ってモニタリングする。ことも可能\n",
    "- 上記CloudWatch EventsとLambda関数でイベント検知可能\n",
    "\n",
    "[**Route53**]<br>\n",
    "- Route53の**ヘルスチェックはトラフィックルーティングにおいてフェールオーバーを実施する際に利用する機能**これを利用しても、インスタンスにエラーが発生した場合にウェブサービスを実行するEC2インスタンスを再開することはできません。\n",
    "- Route53の**位置情報ルーティング**を構成して、特定地域からのアクセスを遮断する機能もある\n",
    "- （注意点）Route53の地理的近接性ルーティングには、特定地域からのアクセスを遮断する機能はありません。必要に応じてトラフィックをある場所のリソースから別の場所のリソースに移動する場合に使用します。\n",
    "- （補足）Amazon CloudFrontを利用した配信設定を行った上で、**AWS WAFを適用して、地理的制限を適用する。**といった設定も可能\n",
    "- 「現在利用しているpintor.comというドメインの静的ウェブサイトをAWS上で構築することになりました。この静的ウェブサイトにはサーバー側スクリプト処理は必要がないため、コスト最適に実装することが求められています。」・・・このようなケースの場合は、**Route53のパブリックホストゾーン内にpintor.comのドメイン設定して、エイリアスレコードに静的ウェブサイトのエンドポイントを指定する。**\n",
    "- Amazon Route 53 エイリアスレコード で、DNS 機能に Route 53 固有の拡張機能が追加されます。エイリアスレコードを使用すると、選択した AWS リソース (CloudFront ディストリビューションや Amazon S3 バケットなど) にトラフィックをルーティングできます。\n",
    "\n",
    "[**Amazon Redshift**]<br>\n",
    "- Amazon Redshift Spectrumを使うことで、S3バケット上に保存されたファイルに対して直接、高度なクエリ処理を実行することが可能になります。Spectrumの実行には数千台までスケールできるインスタンスが用意されており、データセットがエクサバイトを超えても、高速なデータ取り出しと一貫したパフォーマンスを実現します。\n",
    "- **AWSのフルマネージドなデータウェアハウスサービス**で、**大規模なデータ分析を高速かつスケーラブルに行うことができます。** Redshiftは、特に**データの集計、分析、レポーティングに最適化されており、ビッグデータ環境での使用に向いています。**\n",
    "- **小規模利用からペタバイト単位の構造化データまで、複雑な分析クエリを実行でき、スケールアウトも容易に行うことができます。** Amazon Redshift データウェアハウスは、ノードと呼ばれるコンピューティングリソースのコレクションであり、これらはクラスターと呼ばれるグループを構成します。各クラスターは、1 つの Amazon Redshift エンジンを実行し、1 つ以上のデータベースを含みます。\n",
    "- RDSのマルチAZ配置と同様に複数AZに展開が可能\n",
    "- **大規模なトランザクションデータやログデータを集約して、高速にクエリを実行し、ビジネスインテリジェンスツール（例: Tableau、Power BI）で視覚的なレポートやダッシュボードを作成できます。**\n",
    "\n",
    "[**CloudFront**]<br>\n",
    "- CloudFrontは、コンテンツ配信ネットワーク（CDN）で、エンドユーザーに近いエッジロケーションからコンテンツを提供します。CloudFrontを使用することで、ウェブアプリケーションのレスポンス速度を向上させ、ユーザー体験を改善\n",
    "- Amazon CloudFrontのフィールドレベル暗号化を実施して、アップロード時のデータの暗号化を実施することで、ユーザーによるデータアップロード時の暗号化に対するセキュリティレイヤーを追加することができます。さらに、フィールドレベル暗号化では、特定のデータに特定のアプリケーションのみがアクセスできるように制限することができる\n",
    "- フィールドレベル暗号化により、ユーザーが機密情報をウェブサーバーに安全にアップロード\n",
    "- (注意点)**AWS KMSを適用して、アップロード時の暗号化を実施することはできません。**\n",
    "- CloudFrontディストリビューションを作成し、**オリジン（元となるサーバ）としてALBのDNS名を設定**します。これにより、CloudFrontはALBを通じてEC2インスタンスにリクエストをルーティングします。\n",
    "- 必要に応じて、キャッシュ設定や、SSL証明書（HTTPS通信を使用する場合）の設定を行います。\n",
    "- **エッジロケーションによるファイル圧縮処理を実施する。ことで経費削減が可能**\n",
    "   - ビューワーがリクエストヘッダーに Accept-Encoding: gzip を含めるようのリクエストした場合は、CloudFront が自動的に特定のタイプのファイルを圧縮\n",
    "   - CloudFront は各エッジロケーションでファイルを圧縮\n",
    "- **CloudFrontによるキャッシ保持期間を長くすることで経費削減が可能**\n",
    "- （注意点）Amazon EC2インスタンスとALBを利用して動画配信アプリケーションを構成している場合は、**Amazon CloudFrontディストリビューションをEC2インスタンスではなくALBに設定することが必要**\n",
    "- **CloudFrontにACMの証明書を連携して、HTTPS通信を有効化する。ことが可能**\n",
    "- AWS Transfer for SFTPを構成して、SFTPクライアントを使用して、ウェブコンテントをアップロードする。ことも可能\n",
    "\n",
    "[**AWS Transfer for SFTP**]<br>\n",
    "- AWS Transfer for SFTPを構成して、SFTPクライアントを使用して、ウェブコンテントをアップロードすることで、SFTPクライアントを使用したアップロード方式を設定できます。AWS Transfer Family は、AWS ストレージサービスとの間でファイルを送受信できる安全な転送サービスです。Amazon S3 と連携して、安全で高速なデータ転送を可能にします。\n",
    "\n",
    "\n",
    "[**AWS Global Accelerator**]<br>\n",
    "- パブリックアプリケーションの可用性、パフォーマンス、およびセキュリティの向上させるためのネットワークサービス\n",
    "- エッジでパケットをプロキシして最適なエンドポイントグループにルーティングするかを決めることで、TCP または UDP を利用した幅広いアプリケーションのパフォーマンスを向上\n",
    "\n",
    "[**NATゲートウェイ**]\n",
    "- NATインスタンスからNATゲートウェイに移行する決定は、**主に高帯域幅のトラフィック要求に対応するため** これを実現するには「NATインスタンスからNATゲートウェイに移行して、**NATゲートウェイをパブリックサブネットに設定**する。」\n",
    "- プライベートサブネットのルートテーブルにNATゲートウェイを設定する必要がある\n",
    "\n",
    "[**VPCエンドポイント**]\n",
    "- VPCエンドポイントはインターネットゲートウェイ、NATデバイス、VPN接続、またはAWS Direct Connect接続を必要とせずに、**VPCをPrivateLinkのサポート対象のAWSサービスとVPCエンドポイントサービスに接続**\n",
    "- VPC内のEC2インスタンスから、プライベートネットワークを経由して、VPC外に設定されるAmazon DynamoDBテーブルにアクセスする際は、VPCにゲートウェイエンドポイントを構成して、DynamoDBにルートを設定することが必要です。ゲートウェイエンドポイントは、VPC にインターネットゲートウェイや NAT デバイスを必要とせずに、Amazon S3 および DynamoDB への信頼性の高い接続を提供します。ゲートウェイであるため、ルートテーブルでルートを構成する必要があります。\n",
    "- **ゲートウェイエンドポイントは、「DynamoDBとS3のみに適用可能」**\n",
    "- (注意点)DynamoDBテーブル用のエンドポイントにはインターフェースエンドポイントは利用できません。ゲートウェイエンドポイントを利用\n",
    "- （注意点）DynamoDBテーブル用のエンドポイントにはプライベートリンク接続は利用できません。\n",
    "\n",
    "[**CloudFormationテンプレート**]<br>\n",
    "- **Egress: true で「アウトバウンド許可」**\n",
    "- AWS CloudFormationのテンプレートを利用して、AWSリソース設定を定義したJSON/YAMLファイルからプロビジョニングすることができます。 これによって、**テスト環境などのAWSリソース環境をテンプレート化して、自動で展開することが可能**\n",
    "\n",
    "[**CodePipeline**]<br>\n",
    "- CodeDeployやAmazon ECSなどのサービスをパイプラインとして設定することで、コードの開発からデプロイまでのステップをパイプライン化して、自動的に実行できるように制御することが可能\n",
    "- しかしながら、このCodePipelineはインフラ環境のデプロイには利用できません。インフラのデプロイ設定にはCloudFormationなどを利用する必要があります。\n",
    "\n",
    "[**ネットワークACL**]<br>\n",
    "- Network Access Control Listの略で、AWSにおけるVPC (Virtual Private Cloud) 内で使用される、**サブネットレベルのセキュリティ機能**の一つ\n",
    "- ネットワークACLは**ステートレス**です。つまり、リクエストのレスポンスに関する情報を保持せず、インバウンドとアウトバウンドのトラフィックを独立して扱います\n",
    "- **デフォルトのネットワークACLは、すべてのインバウンドおよびアウトバウンドトラフィックを許可**\n",
    "- （注意点）トラフィックやプロトコルタイプに応じて、トラフィック制御に利用される機能であり、**暗号化を達成する方法ではありません。**\n",
    "  \n",
    "[**SQS**]<br>\n",
    "- Amazon SQSを利用して、Amazon EC2インスタンスのコンポーネント間をメッセージを処理して、**並列処理**を実施するワークロードを構成が可能\n",
    "  - (補足)上記の処理がクラッシュした場合は、「もし**可視性タイムアウト**が設定されており有効期限を過ぎれば、別のEC2インスタンスでキューが取得される。」メッセージが受信された直後は、メッセージはキューに残ったままです。他のコンシューマーが同じメッセージを再処理しないように、Amazon SQS は可視性タイムアウトを設定しています。\n",
    "  - メッセージの**デフォルトの可視性タイムアウトは 30 秒です。最小値は 0 秒、最大スケールは 12 時間**\n",
    "  - 視性タイムアウトを設定するには、**ChangeMessageVisibility API**を使用して、適切な可視性タイムアウト値を設定することになります。これを利用して、**他のコンシューマーがメッセージを二重に取得しない待機時間を設定することで、Amazon RDSデータベースに重複データが保存されないようにします。**\n",
    "  - (注意点)**デフォルトでメッセージはデッドレターキューは設定されてない**\n",
    "  - AddPermission API適切な権限を付与するために利用する権限設定\n",
    "  - CreateQueue APIは新しいキューを作成するためのAPI設定\n",
    "  - ReceiveMessage APIは適切な待機時間を設定するための設定です。待機時間を設定するとすべてのコンシューマーがメッセージの取得を待機してしまいますので、処理が遅延\n",
    "- SQSとAuto Scalingを構成する際はCloudWatchメトリックスに基づいてキューの処理量に応じたスケーリングを設定\n",
    "- 完全マネージド型のメッセージキューイングサービスで、マイクロサービス、分散システム、およびサーバーレスアプリケーションの切り離しとスケーリングが可能\n",
    "- 負荷分散が可能\n",
    "- 送信順序を守られることが要件の場合は、「**FIFOキューを利用**」\n",
    "- **メッセージグループID**を利用することで同じグループのメッセージはまとめて送信されるようにFIFOキューを調整することができます。\n",
    "- 優先度の高いキューと優先度の低いキューを用意します。クライアント側ではジョブの優先度に応じて、どちらのキューに登録するか決めます。\n",
    "\n",
    "[**Amazon SNS**]<br>\n",
    "- SNS はブロードキャスト（1対多の配信）が得意\n",
    "  → 1 つの SNS トピックにメッセージを送ると、複数の SQS キューに同時に送信可能\n",
    "- SQS はメッセージの蓄積や遅延処理が得意\n",
    "  → SNS から送信されたメッセージを蓄積し、後で安全に処理できる\n",
    "- イベント通知を起点としたトリガーとして利用し、実処理はSQSに連携してポーリングするというのが標準的なAWSでのアーキテクチャ構成\n",
    "- コンポーネント処理間の連携を確実に実行するには並列処理による負荷分散が可能なAmazon SQSが最適\n",
    "- (注意点)　Amazon SNSにおいてFIFOトピックを利用して、メッセージの送信順序を守ることができますが、**グループ化する仕組みはありません。**\n",
    "- Amazon SNSトピックを作成して、イベント発生をトリガーにしてメッセージを配信する。Amazon SQSキューをSNSトピックのサブスクライバーとして設定する。さらに、そのキューからメッセージを取得するAWS Lambda関数を設定する。・・・ここまですることで「例えばEコマースの企業であれば注文が発生した時点をトリガーにして、異なるタスク処理を実施する複数のコンシューマーグループにデータを送信して、それぞれのタスクを処理をすること」\n",
    "   - (注意点)Amazon SQS FIFOキューを作成して、メッセージを保通知する場合は、非同期通信となるため、複数のコンシューマーに同期的に通知を実施することができません。\n",
    "\n",
    "\n",
    "[**Amazon Kinesis Data Streams**]<br>\n",
    "- デバイスなどから送られる大量のストリーミングデータをリアルタイムに収集、処理して別のサービスに送信するサービス\n",
    "- Amazon Kinesis Data Streamsを使用してデータを収集するように、**KCLを利用してデバイスデータ処理用のコンシューマーアプリケーションを作成することが可能**\n",
    "  - (ex)毎日100GB以上のストリームデータを取得して、集計するリアルタイム処理用のワークロードを構築する\n",
    "  - KCL は、分散コンピューティングに関連する複雑なタスクの多くを処理することで、Kinesis データストリームからデータを消費および処理するためのライブラリを提供\n",
    "  - EC2インスタンスなどにデプロイして利用。ワーカーがシャード数に応じて、ライフサイクル管理(生成/終了)を実施\n",
    "  - KCLは各アプリケーションインスタンスに対応するライブラリです。KCLは分散コンピューティングに関連する複雑なタスクの多くを処理することで、Kinesis データストリームからデータを消費および処理することができます。複数のコンシューマーアプリケーションインスタンス間での負荷分散、コンシューマーアプリケーションインスタンスの障害に対する応答、処理済みのレコードのチェックポイント作成、リシャーディングへの対応などが実行可能です。\n",
    "  - (ex)KCLを利用してデータ処理アプリケーションを構築して、Amazon Kinesis Data Streamsに対してセッションごとにWebクリックをストリーミング処理する。ことも可能\n",
    "- **ログ解析には向いていません。**\n",
    "- KDGはテストデータを簡単に送信可能\n",
    "\n",
    "[**Amazon Kinesis Data Kinesis Firehose**]<br>\n",
    "- 大量のストリーミングデータを取得して、Lambda関数によってETL処理をしつつ、RedShiftやS3などのストレージやデータベースに配信するサービス\n",
    "- （注意点）Amazon Kinesis Data Firehoseによるストリーミングデータのデータ配信処理は**60秒ごとにまとめて実施されるため、リアルタイムデータ処理には向いていません。**\n",
    "- (注意点)**画像データをAmazon S3バケットに配信することはできません。**\n",
    "- ストリームデータを変換したり、ストレージやDBに配信するサービスです。Amazon Kinesis Data Firehoseを利用して、データをAmazon S3データレイクに送信することができます。\n",
    "\n",
    "[**API Gateway**]<br>\n",
    "- API Gatewayに特定のアカウントを指定したスロットリングを追加することで、特定アカウントのユーザーからのアクセスが過多になっていた場合に、そのユーザーからのAPIリクエストを制限することができます。\n",
    "- 「未承認ユーザーからのリクエストをブロックする」には？\n",
    "  - **特定ユーザーのみに付与されるAPIキーを使用する使用量プランを作成する**\n",
    "  - **Amazon API Gatewayを利用してプライベートAPIに設定する。**\n",
    "  - \n",
    "- \n",
    "\n",
    "[**Amazon SWF**]<br>\n",
    "クラウドのワークフロー管理アプリケーションで、複数マシン間でアプリケーションを連携させるためのツールを開発者に提供\n",
    "\n",
    "[**Amazon EMR**]<br>\n",
    "- Apache Sparkなどのソフトウェアを構成して、デバイスなどから送られる大量のストリーミングデータをリアルタイムに収集、分析するサービス\n",
    "- Amazon EMRは、動的にスケーラブルなAmazon EC2インスタンス全体で膨大な量のデータ処理を簡単、高速、そして費用対効果の高いものにするマネージド**Hadoopフレームワーク**を提供します.\n",
    "- Webインデックス作成、データマイニング、ログファイル分析、機械学習にむいてる\n",
    "\n",
    "[**Amazon Inspector**]<br>\n",
    "- 自動化されたセキュリティ評価サービスで、AWS にデプロイしたアプリケーションのセキュリティとコンプライアンスを向上させることができます。EC2インスタンスにエージェントをインストールして、そこにホストされたアプリケーションの意図しないネットワークエクスポージャーなどの脆弱性を検知\n",
    "\n",
    "[**Amazon GuardDuty**]<br>\n",
    "- Amazon S3 ログ、CloudTrail 管理イベントログ、DNS ログ、Amazon EBS ボリュームデータ、Kubernetes Audit Logs、Amazon VPC フローログ、RDS ログインアクティビティの AWS CloudTrail データイベントなどのデータソースを分析して、DDoS攻撃以外の様々なネットワークへの不正アクセスを自動的に検知\n",
    "\n",
    "[**AWS Compute Optimize**]<br>\n",
    "- EC2インスタンスタイプ、Amazon Elastic Block Store (EBS) ボリューム、AWS Lambda 関数の 3 種類の AWS リソースの過剰プロビジョニングや過小プロビジョニングなどの利用状況に基づいて、コスト最適化のアドバイスを実施\n",
    "\n",
    "[**Amazon ALB**]<br>\n",
    "- ALBは**レイヤー7の負荷分散を行い、アプリケーションレベルでのルーティングや、ヘルスチェックをサポート**します。\n",
    "\n",
    "[**AWS Data Pipeline**]<br>\n",
    "- AWSサービス間のデータ転送や変換処理に利用されるサービスであり、ストリームデータを取得・変換する際には利用できません。AWS Data Pipeline は保存場所にあるデータに定期的にアクセスし、データの変換と処理を行い、その結果を Amazon S3、Amazon RDS、Amazon DynamoDB、Amazon EMRなどのAWS サービスに効率的に転送\n",
    "\n",
    "\n",
    "[**AWS Fargate**] <br>\n",
    "- AWS Fargateは、Amazon Web Services（AWS）が提供する**サーバーレスコンテナサービス**で、コンテナの管理やインフラのプロビジョニングを自動化することができます。Fargateを使用すると、コンテナの実行に必要なサーバーやインスタンスを管理することなく、アプリケーションを展開できる\n",
    "- Fargateは、コンテナの実行に必要なサーバーリソースを自動で割り当て、スケールします。**開発者はコンテナの実行に必要なリソース（CPU、メモリなど）を指定するだけで、インフラの設定や管理を行う必要はありません。**\n",
    "- Fargateは、コンテナの負荷に応じてリソースをスケールできます。\n",
    "- AWS Fargateは、Amazon ECS（Elastic Container Service） や Amazon EKS（Elastic Kubernetes Service） で動作します。これにより、Fargateを使ってコンテナ化されたアプリケーションをECSやEKSの管理下で簡単にデプロイできます。\n",
    "- Amazon ECSクラスターをAWS Fargateを起動タイプを利用してプロビジョニングすることで要件を達成することができます。**コンテナをFargateタスクにデプロイすることで、コンピューティングリソースをサーバレスに起動・スケールすることができるため、コンテナオーケストレーションの管理オーバーヘッドをなるべく抑制しつつ、タスクを利用したマイクロサービスを構成することができます。**\n",
    "\n",
    "[**Amazon ECS**]<br>\n",
    "- Amazon ECS は、コンテナ化されたアプリケーションを簡単にデプロイ、管理、スケーリングすることができるフルマネージド型のコンテナオーケストレーションサービスです。**Amazon ECS はコンテナ構成時に、EC2インスタンスをコンテナに利用するEC2起動モードと、サーバレスコンピューティングサービスであるFargate起動モードを選択することができます。**\n",
    "- Amazon ECSコンテナから他のAWSリソースにアクセスをする際は、タスクに対して、そのサービスへのアクセス許可が設定されたIAMポリシーを付与したIAMロールを設定することが必要\n",
    " - タスク IAM ロールはtaskRoleArn API オペレーションによって定義できます。\n",
    " - (注意点)　**IAMロールはAmazon ECS コンテナインスタンスに設定するのではなく、タスクに設定する必要があります。**\n",
    " - (注意点) タスク実行ロールは、ECS コンテナエージェントがタスクを実行（起動）するときに必要なロールを定義するものであり、コンテナ自体の動作権限を付与するものです。タスクに対して、その他のAWSサービスへのアクセス許可をするためのロールではありません。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fc189-87b7-4e1b-b7fd-fb0222c9e254",
   "metadata": {},
   "source": [
    "### 知見,アーキテクチャ設計ユースケース\n",
    "[**CloudFrontとHTTP領域**]<br>\n",
    "CloudFrontを利用しグローバルにコンテンツを配信することを考えた場合「言語処理」\n",
    "を例えば以下のようにHTTP領域にて展開する方法もある。パラメータをこれで送ることが可能\n",
    "- http://pintor.cloudfront.net/index?language=jp\n",
    "- http://pintor.cloudfront.net/index?language=en<br>\n",
    "この場合は「クエリ文字列パラメーター値に基づくキャッシュ設定を行うことでHTTPフィールド内の言語表示に基づいて配信方法を切り替えること」で実現可能\n",
    "\n",
    "(補足)<br>\n",
    "クエリ文字列（URLパラメーター）とは、サーバーに情報を送るためにURLの末尾につけ足す文字列（変数）のことです。「?」をURLの末尾につけ、その次に「パラメーター＝値」をつけ、複数のパラメーターをつけたい場合は「&」を使用します。この形式で、サーバーに送信したいデータをURLにつけ加えることが可能\n",
    "\n",
    "[**SQSによるマイクロサービス化されたコンポーネントとの連携処理**]<br>\n",
    "マイクロサービス化されたコンポーネント間の処理を連携する際は、Amazon SQSを利用したポーリング処理が最適となります。\n",
    "例えば：Amazon ECSを活用してマイクロサービス型のアプリケーションを構築しています。 このアプリケーションのアーキテクチャでは、マイクロサービス１とマイクロサービス２に分割し、マイクロサービス１の処理後にマイクロサービス２に処理が引き渡されます。\n",
    "]\n",
    "\n",
    "[**IoTセンサーに基づいたデータ分析**]<br>\n",
    "上記のようなケースではまさに「Amazon Kinesis Data Streams」を活用すべき。Amazon Kinesis Data Firehose経由でAmazon S3バケットに送信。<br>\n",
    "注意点として「デフォルトでは、データレコードがAmazon Kinesis Data Streamsに投入されてから24時間以内までアクセスできるように設定されている。」\n",
    "\n",
    "[**ELBから結合されたログファイルを分析できるようにアプリケーションを構築**]<br>\n",
    "Amazon S3に対してELBのログファイルを収集し、Amazon EMRでログ解析を実施する方法が考えられる。\n",
    "ログファイルの収集場所としてはAmazon S3が適切。このログファイル分析には大量データ解析が可能なパフォーマンスが必要\n",
    "\n",
    "[**エッジ処理とは？**]<br>\n",
    "「エッジ処理」とは、CloudFrontエッジロケーションで実行される処理のことを指します。エッジロケーションでは、リクエストの処理が行われる際、以下のような処理が実施されることがあります：\n",
    "- コンテンツキャッシュ: CloudFrontエッジサーバーが、ウェブサイトの静的コンテンツ（HTML、画像、動画、CSS、JavaScriptなど）をキャッシュし、リクエストがあるたびに高速に返します。これにより、リクエスト元のサーバー（オリジンサーバー）への負荷を軽減し、応答速度を向上させます。\n",
    "- リクエスト/レスポンスのカスタマイズ: CloudFrontは、Lambda@Edgeという機能を使って、リクエストやレスポンスに対してカスタマイズを行うこともできます。これにより、リダイレクトや認証、リクエストヘッダーの変更、レスポンス内容の変更など、エッジでの処理を行えます。\n",
    "- 動的コンテンツの処理: 一部の動的コンテンツ（例えば、ユーザーごとに異なるデータを提供するAPIレスポンスなど）も、エッジサーバーで処理され、オリジンサーバーへのアクセスが減少します。これにより、コンテンツ配信が迅速になります。\n",
    "\n",
    "[**データベース障害を抑止するソリューションとコスト最小限で１つのデータセンターに依存した構成**]<br>\n",
    "- **データを同期的にレプリケートするようにマルチAZ配置を有効にしたAmazon RDS DBインスタンスを構成**する。\n",
    "\n",
    "[**Amazon S3に保存されているデータにアクセスする必要がありますが、 トラフィックはインターネットを通過できない場合は？**]<br>\n",
    "- **VPCのプライベートサブネットにインターフェースエンドポイントを設定**して、IPアドレス経由でアクセスする。\n",
    "\n",
    "[**EC2インスタンス側の暗号化はどうやるの？**]<br>\n",
    "- 利用している**EBSボリュームの有効化**を実施する必要があります。Amazon EBSボリュームは**AWS KMSと連携**して暗号化キーを利用して、容易にデータを暗号化することができます。\n",
    "\n",
    "[**Amazon S3の保存データを保護するには？**]<br>\n",
    "- サーバーサイド暗号化を使用つまり、**オブジェクトをデータセンターのディスクに保存する前にAmazon S3で暗号化**し、オブジェクトを**ダウンロードするときに復号化**するように要求します。S3のデフォルト暗号化を有効化する際に、**SSE-S3**と**SSE-KMS**のどちらかの暗号化形式を選択\n",
    "- クライアントサイド暗号化を使用つまり、データをクライアントサイドで暗号化し、暗号化されたデータをAmazon S3にアップロードできます。この場合は、暗号化プロセス、暗号化キー、および関連ツールを管理\n",
    "\n",
    "[**SSL/TLS証明書を用いた基礎**]<br>\n",
    "- セキュリティ要件として、保管中およびAWSに転送中のデータを保護するための方策の場合は、SL/TLS証明書を利用して、HTTPSプロトコルを利用した通信を実施しています。を使用するロードバランサ（SSLオフロードとも呼ばれる）を作成できます。この機能により、ロードバランサーとHTTPSセッションを開始するクライアント間、およびロードバランサーとEC2インスタンス間の接続のトラフィック暗号化が有効\n",
    "\n",
    "[**S3バケットのコンテンツをCloudFrontディストリビューションから配信する際に、S3 オブジェクトURLに直接アクセスできないようにしてから、WAFを適用することが求められるケースでは？**]<br>\n",
    "- Amazon CloudFront側でオリジンアクセスアイデンティティ（OAI）またはオリジンアクセスコントロール (OAC) を作成し、そのOAIまたはOACにのみ読み取りアクセスを許可するようにS3バケットポリシーを設定\n",
    "- こうすることで、OAIまたはOACのみがS3バケットにアクセスできる構成となり、CloudFrontはOAIまたはOACを介してS3バケットのコンテンツにアクセスして配信処理を行います。\n",
    "\n",
    "\n",
    "[**既存のEC2インスタンスからAmazon RDS DBインスタンスへのアクセスがIPアドレスを経由して設定されています。Auto Scalingグループから新しいインスタンスが起動する際に、データ処理時にエラーが発生どうする？**]<br>\n",
    "- Amazon RDSのセキュリティグループにおいて、EC2インスタンスに設定されたセキュリティグループIDをターゲットにして、3306ポート番号のアクセス許可を設定する。Auto Scalingグループで選択する起動テンプレート設定で同じセキュリティグループを利用する。\n",
    "\n",
    "[**DB構成を変更して、DBインスタンスの高可用性、読み取りワークロードの容量の増加、および書き込みレイテンシーの低減を最大限に達成するには？**]<br>\n",
    "- 既存のデータベースを**Amazon RDS マルチAZクラスター配置に変更する。** 書き込みリクエストはプライマリのDBインスタンスで処理して、読み込みリクエストはリードレプリカで処理する。\n",
    "\n",
    "[**アプリケーションに対するHTTPエラーを検出して、これらのエラーが発生した場合、ウェブサービスを実行するEC2インスタンスを自動で再開する必要があります。この要件を満たすためには？**]<br>\n",
    "-**ALBの異常なターゲット数をモニタリングするAmazon CloudWatchアラームを作成する。アラームがALARM状態になると異常状態のインスタンスを置換するように、Auto Scalingアクションを構成する**\n",
    "- **Unhealthyhostcountのメトリクス**をモニタリングするAmazon CloudWatchアラームを作成\n",
    "\n",
    "[**起動時にEC2インスタンスがソフトウェアと共にプレインストールされるように設定する必要があります。**]<br>\n",
    "- ユーザーデータにインストール用のBashスクリプトを加える。またはゴールデンイメージを作成して、起動設定を設定する。\n",
    "\n",
    "\n",
    "[**特定の期間に高負荷が予想されており、かつ、一定の処理負荷になった場合にもスケーリングを自動で実行すること設定はどうする？**]<br>\n",
    " - 動的オートスケーリングの**ターゲッツ追跡スケーリングポリシー**によって、一定のCPU利用に応じてスケーリングを実行\n",
    " - あらかじめスケーリング実施期間を設定することが可能となります。**スケジューリングによるオートスケーリングを設定**することで、特定の期間にスケーリングを実行\n",
    " - (注意点)ステップスケーリングポリシーは動的スケーリングにおいて、スケールさせるインスタンス数を段階的に増やすステップなのでこのケースでは不適切\n",
    "\n",
    "\n",
    "[**S3による複数ドメインを利用した静的ウェブサイトの構築におけるAjax通信の設定は？**]<br>\n",
    "- **Amazon S3バケットのCross-Origin Resource Sharing (CORS)を有効化する。ことで実現が可能**\n",
    "- CORSは、特定のドメインにロードされたクライアントウェブアプリケーションが異なるドメイン内のリソースと通信する方法を定義\n",
    "\n",
    "[**複数リージョンに冗長化された構成が必要となったため、EC2インスタンスに接続されているEBSボリュームを東京リージョンから、別のリージョンに移動させたい・・どう構築する？**]<br>\n",
    "- 対象のEBSのスナップショットを作成して別リージョンでEBSボリュームを複製する。\n",
    "\n",
    "\n",
    "[**Amazon RDS DBインスタンスを利用し書き込み処理と読み取り処理を分割することが必要です。この要件を満たすために、最も効果的なDB構成は？**]<br>\n",
    "- プライマリDBインスタンスと同じコンピューティングリソースを利用して、リードレプリカを追加する。書き込みリクエストはプライマリのDBインスタンスで処理して、読み込みリクエストはリードレプリカで処理することが可能\n",
    "\n",
    "[**今後数年は利用するアプリケーションですが夜間や休日はあまり使用されないため、負荷が一定ですが、不定期に日中は負荷が急増する、、アプリケーションの可用性に影響を与えることなく、EC2インスタンスのコストを削減するには？**]<br>\n",
    "- **通常処理に必要なベースラインキャパシティにはリザーブドインスタンスを使用する。アプリケーションの負荷増加に対してはスポットインスタンスを利用**\n",
    "   - ワークロード全体に対してリザーブドインスタンスを使用してしまうと、負荷急増時のキャパシティまで考慮して最大数を予約購入することになるため、コスト最適になりません。\n",
    "   - （補足）１年１カ月利用していたインスタンス等の場合は、３年間前払いしていることを意味しています。そのため、リザーブドインスタンスをただシャットダウンするだけでは前払い分を損してしまいます。したがって、マーケットプレイスで販売することが必要。またその際に「**EBSボリュームのスナップショットを取得しインスタンスを停止することで、データのみを保持することができます。**」\n",
    "\n",
    "[**HTTPトラフィックとHTTPSトラフィックを別々に処理するALBのリクエストがすべてHTTPSを使用するように構成しなおす方法は？**]<br>\n",
    "- Application Load Balancer のリスナールールを使用して、HTTP リクエストを HTTPS にリダイレクトする設定を利用します。ALBのリスナー設定において、[リダイレクト先] として port 443 （デフォルトのポート以外を使用する場合はその値）を指定することで、HTTP リクエストを HTTPS にリダイレクトされるように設定すること\n",
    "\n",
    "[**S3バケットを利用したコンテンツ共有の仕組みを構築しています。このコンテンツ共有を利用するユーザーからのアクセスに限定する必要があり、インスタンスのIPアドレスからのみオブジェクトにアクセスできるように設定することが要件となっています。この要件を達成するには？**]<br>\n",
    "- **Amazon CloudFrontにおいてOAIを作成して、Amazon S3バケットポリシーにOAIのみにアクセス許可を設定**\n",
    "- **CloudFrontを設定してWAFの IP ホワイトリストを実施する。**\n",
    "- (補足) WAFのWEB ACLによる制御をReferer制限と呼びます。\n",
    "\n",
    "[**単一のデータセンター障害に停止することなく、アプリケーション処理を継続できる構成は？**]<br>\n",
    "- 2つのアベイラビリティゾーンそれぞれにまたがって、２つのEC2インスタンスを起動して、それぞれをELBターゲットグループに設定する。その上で、ターゲットグループに対して２つのアベイラビリティゾーンに指定したAuto Scalingグループを構成する。\n",
    "\n",
    "[**EC2インスタンスの状態の変更発生などをモニタリングする方法を模索しています。要件としてはインスタンスの状態を監視し、各状態の変化が発生した時点をトリガーとして、データベースに変更状況を記録するにはどうする？**]<br>\n",
    "- Amazon EventBridgeを利用してインスタンスの状態変化をトリガーにして、アクションを設定する。\n",
    "- Lambdaファンクションを利用して状態記録をDynamoDBに蓄積する。\n",
    "\n",
    "[**アプリケーションのスタックを複数のマイクロサービスに分割して疎結合化すること、その際は、コンテナを利用してマイクロサービスを作成するが運用要件として、AWS上でコンテナ用コンピュートリソースの構成管理が必要ないこと、この要件を満たすには？**]<br>\n",
    "- **Amazon ECSクラスターをFargate起動モードでプロビジョニングする。コンテナにFargateタスクをデプロイする。**\n",
    "- (補足) AWSではDocker形式のアプリケーション開発環境を提供するAmazon ECSと、kubernetesと呼ばれる形式のコンテナー仮想化を実現するAmazon EKSの２つのサービスが利用可能です。その中で利用できるコンピューティングエンジンにはサーバータイプのEC2起動タイプとサーバレスで実行可能なFargate起動タイプの２種類から選択することができます。\n",
    "- (補足)　AWS Fargateはインスタンスのタイプやサイズなどのプロビジョニング設定を自動で構成してくれるため、Dockerコンテナのコンピューティング設定や運用管理が自動化できます。\n",
    "- (補足)　**Amazon ECRはDockerイメージというファイルを保存するサービス**です。イメージはDockerコンテナ構成を保存して、再利用することができます。\n",
    "\n",
    "\n",
    "[**LambdaファンクションがDynamoDBテーブルを操作できるように権限を設定する必要,どのように権限を設定する？**]<br>\n",
    "- Lambdaファンクションに**IAMロールを設定**してDynamoDBへのアクセスを許可する。\n",
    "\n",
    "[**オンプレミス環境上の静的ウェブサイトをAWSに移行することを決定、できるだけ迅速に世界中のユーザーが閲覧できる必要があり、コスト最適なアーキテクチャが求められている、何を実施するべき？**]<br>\n",
    "- 静的WEBサイトをAmazon S3から配信するように静的ウェブホスティングをS3バケットに構成する。Amazon CloudFrontを構成し、S3バケットをオリジンとして設定する。\n",
    "- この静的WEBホスティングを有効化したS3バケットをオリジンサーバーとしてCloudFrontに構成します。これによって、エッジロケーションを介して、静的WEBサイトのコンテンツをグローバルに高速に配信することができます。\n",
    "- （補足）静的WEBホスティングを設定したS3バケットに対してRoute53を構成して、ドメインを設定することができます。しかしながら、グローバルなコンテンツ配信を最適化する場合はCloudFrontを利用する必要があります。\n",
    "\n",
    "[**SNSとSQSを組み合わせたアーキテクチャの仕組み**]<br>\n",
    "(設定方法)\n",
    "1. Amazon SNS トピックを作成\n",
    "「トピック」とは、メッセージを送信するための ブロードキャストチャンネル のようなもの\n",
    "例: OrderEventsTopic（注文関連のイベント通知トピック）\n",
    "2. Amazon SQS キューを作成\n",
    "キュー とは、SNS から送信されたメッセージを受け取り、一時的に蓄積するもの\n",
    "例: OrderProcessingQueue（注文処理用の SQS キュー）\n",
    "3. SQS キューを SNS トピックにサブスクライブ\n",
    "OrderProcessingQueue を OrderEventsTopic にサブスクライブ（登録）\n",
    "SNS にメッセージが送られると、自動的に SQS にもメッセージが送信される\n",
    "4. 必要なら IAM ポリシーを設定\n",
    "SQS キューが SNS からのメッセージを受け取れるように アクセス許可（IAM ポリシー） を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbb798-0f2c-49ad-a453-43cb6982eb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
