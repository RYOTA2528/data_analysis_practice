{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e427e8f2-ad78-4022-b6f1-c1d53f274512",
   "metadata": {},
   "source": [
    "### 模擬試験でのポイント\n",
    "\n",
    "\n",
    "[**IAM**]<br>\n",
    "- IAMポリシーは、**IAMユーザーやIAMロールに対する権限範囲を規定する記述文書**です。これによって権限範囲を詳細に設定することができます。しかしながら**IAMポリシーによって定められた権限範囲をリソースに付与する際はIAMロールが必要**となります。\n",
    "- IAMユーザーは**ユーザーアカウントの権限設定**に利用します。**リソースに対するアクセス権限設定にはIAMロール**を利用\n",
    "- IAMロールをEC2インスタンスに設定してDynamoDBへの読取を許可することなども可能\n",
    "- IAMロールを使用してS3バケットへの特定のアクセスを必要とするEC2インスタンスにアクセス権限を付与することができます。\n",
    "- **バケットポリシーでもアクセス制御ができますが、特定のユーザー単位**でのアクセス制御を主としており、特定IPのEC2インスタンスからのアクセス制御にはIAMロールの方が最適\n",
    "- **S3においてIAMポリシーはアクセス許可範囲を特定のバケットに限定することが可能**\n",
    "- これらIAMによる設定で「S3 APIのアクセスを制限することが必要」なケースに対応可能\n",
    "- (注意点)またGlacierはS3のストレージクラスのタイプとなっているため、バケットポリシーでS3バケットのデータをGlacierにバックアップするアクセスを制限することはできません。\n",
    "- IAMアクセスキーは「AWSユーザーのプログラム認証に利用する認証方式です。**CLIツールなどを利用する際**に設定します。」\n",
    "- **IAMポリシーで「 \"ec2:TerminateInstances\"」とは「全てのEC2インスタンスの終了させるアクション」**\n",
    "\n",
    "\n",
    "[**Amazon EC2**]<br>\n",
    "- backupを取得するには、**EC2インスタンスを停止し、各EC2インスタンスボリュームのスナップショットを個別に作成する。** スナップショットが完了したら、EC2インスタンスを起動し、関連するすべてのボリュームが再マウントされていることを確認する\n",
    "- EC2インスタンス間を通信するためには**プライベートIPアドレスを指定すること**で実施できます。\n",
    "- EC2インスタンス間を通信するために、**Elastic IPは必要ありません。**\n",
    "\n",
    "[**カスタマーゲートウェイ**]<br>\n",
    "- **カスタマーゲートウェイに静的ルートテーブルを構成**して、パブリックおよびプライベートの AWSネットワークに接続するための仮想インターフェイスへのルートを設定することで、VPC接続を構成\n",
    "- Amazon VPC VPN 接続では、データセンター (またはネットワーク) を Amazon VPC 仮想プライベートクラウド (VPC) にリンクします。カスタマーゲートウェイは、その接続の作業者側のアンカーです。\n",
    "- (注意点) Route53はVPN接続には利用できません。\n",
    "\n",
    "[**Direct Connect**]<br>\n",
    "- AWSとオンプレミス環境間の専用線接続サービスです。Direct Connectを構成した上で、**IPsecを追加**することができます\n",
    "\n",
    "[**Egress Only-インターネットゲートウェイ**]\n",
    "- IPv6 経由で プライベートサブネット からインターネットへの送信を可能にするゲートウェイ\n",
    "\n",
    "[**AWS Organizations**]<br>\n",
    "- 複数アカウントをメンバーアカウントとしてグループ化した**OUに対して、サービスコントロールポリシー(SCP)を設定する**ことで、複数アカウント内で設定で切るAWSリソースのアクション権限範囲を管理することができます。\n",
    "- SCP内で許可した範囲においてIAMポリシーによるアクセス権限付与が実行できるアカウント\n",
    "  - (イメージ)IAM(EC2・ECSへの許可)、SCP(EC2、RDS・ECSの許可)=EC2・ECSの許可のみ\n",
    "  - **ユーザーに対してアクセス許可権限を付与しません。**\n",
    "- AWS Organizationsはアカウントで **IAM ロールを使って、特定のAWSアカウントのリソースへのアクセス権を別の AWS アカウントに付与**できます。\n",
    "\n",
    "[**AWS Storage Gateway**]<br>\n",
    "- **Amazon S3バケットとオンプレミスストレージ**を接続して、**バックアップを取得**したり、**ストレージ容量を拡張**したりすることができるハイブリッドクラウド機能を提供\n",
    "- **保管型ボリューム**を使用すると、**プライマリデータをローカルに保存する**一方で、そのデータを非同期に AWS にバックアップします。\n",
    "- 上記は「Amazon Elastic Block Store **(Amazon EBS) スナップショットとして Amazon S3 に非同期でバックアップ**」される\n",
    "- **キャッシュ型ボリューム**を使用することで、頻繁にアクセスされるデータはローカルのストレージゲートウェイに保持しながら、**Amazon S3 をプライマリデータストレージ**として使用\n",
    "- つまり保管型が「AWSクラウドにストレージを拡張するケース」で用いられる\n",
    "\n",
    "[**Amazon FSx for Windows File Server**]<br>\n",
    "- **AWS Managed Microsoft AD ディレクトリを利用した認証を設定することが必須**となります。したがって、AWS Managed Microsoft AD ディレクトリを構成した上で、このADを認証基盤に利用して Amazon FSx for Windows File Serverを構成し、このファイルシステムをWindowsインスタンスにマウント\n",
    "\n",
    "[**S3**]<br>\n",
    "- バケットポリシーは**Amazon S3バケットのアクセス制御をバケット側で設定することができるポリシー**\n",
    "- Amazon S3バケットは**バケットポリシーの設定許可があり、かつ、パブリックブロックアクセスが無効化されている場合に、インターネットから誰でもオブジェクトデータにアクセスできることが可能なストレージ**\n",
    "- また、バケットポリシーの設定により、インターネットからのバケットへの**s3:GetObject を設定する必要があります。**\n",
    "- **CloudFrontにおいて署名付きURLおよび署名付きCookiesを利用することで、Amazon S3の事前署名付きURLと同じような効果を達成することができます。** これらはAmazon S3の事前署名付き URLと同じような機能を提供します。\n",
    "- S3バケットの**オブジェクトロック**の**コンプライアンスモードでは、指定した保持期間中にS3バケット内のオブジェクトに対してデータ変更や削除ができなくなります。**\n",
    "- **コンプライアンスモードでは、AWS アカウント の root ユーザーを含め、ユーザーが、保護されたオブジェクトのバージョンを上書きまたは削除することはできません**\n",
    "- **ガバナンスモードでは、必要に応じて一部のユーザーにリテンション設定の変更、またはオブジェクトの削除を許可することができます。**\n",
    "- (注意点)**オブジェクトロックの有効化は、S3バケットを作成する際にしか実施できません。**\n",
    "- (注意点)**バケットポリシーにWAFを設定することができない。WAFはCloudFrontに設定する必要があります。**\n",
    "- 「データ量を抑えるために保存後に1ヶ月以上すぎた場合は対象ビデオデータを削除すること」の要件をかなえるには**S3 Standard IAにビデオを保存してライフサイクルポリシーで1か月後に削除する。**\n",
    "- Amazon S3バケットの**GetObject権限を付与するAssumeRoleを実施するIAMロールを作成して、特定のユーザーにのみ権限を委譲することで、クロスアカウントアクセスを可能にします。**\n",
    "- **AsumeRoleを利用することで IAM ロールに設定された権限を移譲することができます。**\n",
    "- ドキュメント管理システムでは頻繁にドキュメントの変更が発生するため、**Amazon S3バケットのバージョニングを有効化して、適切なバージョン管理を実行**\n",
    "- **Amazon S3 Transfer Acceleration** を使用すると、クライアントと S3 バケットの間で、長距離にわたるファイル転送を高速、簡単、安全に行えるようになります。\n",
    "- **各オブジェクトの現在の日付をプレフィックスとして付与することで読み取りと書き取りのトラフィック量が増大すると予想されているアプリでもパフォーマンスを最大化できる**\n",
    "- Amazon Glacier **Flexible Retrieval**では**標準取り出しでは、 3〜5 時間以内にすべてのアーカイブにアクセスできます。**\n",
    "- **迅速取り出しでアクセスしたデータは通常 1〜5 分以内で使用可能になります。**\n",
    "- **大容量取り出しはGlacier の最も安価な取り出しオプションであり、これを使用して大量のデータ (ペタバイトのデータを含む) を 1 日以内に取得できます。通常、大容量取り出しは 5〜12 時間必要であるため、10時間以内に対応できません。**\n",
    "- \n",
    "  \n",
    "[**セキュリティーグループ**]<br>\n",
    "- **セキュリティグループの変更と新規設定は全てのEC2インスタンスに即座に反映されます。**\n",
    "\n",
    "[**AWS Glue**]<br>\n",
    "- **AWS Glue は抽出、変換、ロード (ETL) を行う完全マネージド型のサービスで分析用データの準備とロードを簡単にします。** これを利用して、S3からデータを抽出し、ターゲットスキーマに自動的に一致するようにデータを変換することが可能です。AWSに保存されたデータを指定するだけで AWS Glue によるデータ検索が行われ、テーブル定義やスキーマなどの関連するメタデータが AWS Glue データカタログに保存されます。\n",
    "\n",
    "[**インターネットゲートウェイとルーティング**]<br>\n",
    "- **パブリックサブネットとしてインターネットからのアクセスを許可するためにはインターネットゲートウェイが必要**です。設定としては、このEC2インスタンスにはインターネットから自由にアクセスするWEBサイトを構築する予定であるため、インターネットゲートウェイに対して**0.0.0.0/0でフルオープンを設定**することが求められる(**Destination：0.0.0.0/0  - >Target：インターネットゲートウェイ**)\n",
    "- 「**VPC内に設置したEC2インスタンスに対してインターネットからアクセスできない場合**」は以下の要因が考えられる\n",
    "  - **インターネットゲートウェイがサブネットに設定されていない。\n",
    "  - ネットワークACLの設定でインターネットアクセス許可が設定されていない。\n",
    "  - セキュリティグループの設定でインターネットアクセス許可が設定されていない。\n",
    "  - パブリックIPアドレスが付与されていない。\n",
    "\n",
    "[**AWS Certificate Manager**]<br>\n",
    "- **AWS Nitro Enclaves**を利用したインスタンスを利用することで、**EC2インスタンスにAWS Certificate Manager上のSSL証明書を設定できるようになりました。** その際は、**特定のIAMロールに証明書を関連付けて、** AWS Nitro Enclavesを利用したインスタンスに対して、そのIAMロールを設定することが必要となります。\n",
    "- **既存のSSL証明書をAWS Certificate ManagerにインポートしてAWS上で利用**することができます。そして、**ACMからSSL証明書を実施するHTTPSリスナーを持つALBを設定**することで、**クライアントからALBへの通信を暗号化**することが可能となります。ALBでは、暗号化用の HTTPS リスナーを作成して、ACMのSSL証明書を設定することで、暗号化通信を実施します。この機能によって、**ロードバランサーと SSL あるいは TLS セッションを開始したクライアント間のトラフィックを暗号化できます。**\n",
    "- **AWS Certificate ManagerのSSL証明書はAmazon CloudFrontやELBに設定することが必要**\n",
    "- **(注意点)ALBにACM証明書を設定する際はTSLリスナーではなく、 HTTPS リスナーを利用**\n",
    "- (補足)**ACM証明書の有効期限をチェックするAWS Configルールによっても、有効期限が切れる予定の証明書を検出することは可能**ですが、**ConfigからSNS通知を直接に設定することが可能**です。**CloudWatchアラートを使って通知設定をする必要はありません。** AWS Config は、変更が発生したときに Amazon SNS を使用して通知を配信します。\n",
    "\n",
    "[**Auto Scalingグループ**] <br>\n",
    "- Auto Scalingでは、**スケーリングがうまく実行されずに24時間以上たった場合は、自動的にAuto Scaling処理が停止するようになっています。**\n",
    "- インスタンスの起動を繰り返し、24時間失敗し続けるとAmazon側で停止する可能性がある\n",
    "- **インスタンスの状態がImpairedになると、数分間リカバリーされるかチェックする**\n",
    "- **AutoScalingを一時的に停止しないでインスタンスを停止すると新規インスタンスが起動してしまう**\n",
    "- **ステップスケーリングポリシーは、CloudWatchメトリクスから得られる値（CPU使用率やSQSキューサイズなど）の閾値を超えて発せられるアラームに対して、値ベースでスケーリングアクションを個別設定できる機能**\n",
    "- 現在のスケーリング設定では**短期間にスケールアウトとスケールインを繰り返し**ており、問題となっています。この状況を改善するために必要となるスケーリング設定は・・\n",
    "  - Auto Scalingグループの**クールダウンタイム値を最適化する。**\n",
    "  - **Auto Scalingのスケールアウト時のポリシーをステップスケーリングポリシーにすることで、インスタンス増減をより詳細に制御する。**\n",
    "- **ターミネーションポリシーはスケールイン時のインスタンスを終了させる方法を定義するポリシー**\n",
    "- AutoScalingによって新規インスタンスが起動されましたが、新規インスタンス数の増加によるパフォーマンス向上効果が発揮されるまで遅いことが問題・・・その場合は「**AutoScalingのステップスケーリングポリシーによってウォームアップ条件を設定する。**」ことで改善\n",
    "  - これまでのスケーリングでは、単純にCPU使用率上がったら沢山インスタンスを追加してしまうといった実際のビジネスにフィットしないケースがありました。そこで、50%なら1台追加、60%なら2台追加、70%なら3台追加といった具合に、閾値を超えてアラームから報告される値によってスケールする台数を指定\n",
    "- スケジュールされたスケーリングでは、独自のスケーリングスケジュールを設定できます。これは負荷が高まる期間がわかっている際に利用\n",
    "- **EC2インスタンスのWEBサーバーにおいてAuto Scalingを設定している場合は、Auto Scalingグループと既存のEC2インスタンスに利用されているセキュリティグループを統一した上で、そのセキュリティグループIDをDB側のセキュリティグループに設定する方が最適**\n",
    "\n",
    "[**Amazon CloudWatch**]<br>\n",
    "- AWSのリソース（EC2、RDS、Lambdaなど）の監視や、カスタムメトリクスの収集・アラート設定を行うサービスです。CloudWatchを使ってシステムの状態を監視し、**Auto Scalingのトリガーとして利用することができます。**\n",
    "- Auto Scalingグループを作成した後、CloudWatchアラームを設定して、スケーリングのトリガーとして使用できます。\n",
    "- **CPU使用率とディスクの読み取りメトリクスを組み合わせたCloudWatch複合アラームを作成して、両方のメトリクスに応じた通知を設定なども可能**\n",
    "- **CPU使用率が7０％以上に増加した場合にスケーリングするためには、ステップスケーリングポリシーではなく、ターゲット追跡スケーリングポリシーを設定**します。ステップスケーリングポリシーは複数段階の閾値を設定して、負荷上昇に応じて徐々にインスタンス数を増加させる際に利用するスケーリングポリシーです。**１つの値を閾値に設定してスケーリングする際はターゲット追跡スケーリングポリシーを設定します。**\n",
    "- CloudWatchを利用して複数のメトリクスを指定して複合アラームを設定します。**Amazon EventBridgeはイベントに基づいてアクションを実施する機能であり、メトリクスに基づいたアクションは設定できません。** たとえば、**インスタンスの状態が保留中から実行中に変更されると、Amazon EC2 はイベントを生成します。**\n",
    "\n",
    "[**Amazon EFS**]<br>\n",
    "- **EFS のライフサイクル管理では「費用対効果の高いファイルストレージを自動的に管理します。有効にすると、ライフサイクル管理は 30 日間アクセスされなかったファイルを EFS IA ストレージクラスに自動的に移行します。** ライフサイクル管理によってファイルが IA ストレージクラスに移動されると、**無期限にデータが残ります。削除をするわけではない**」\n",
    "- 「プライベートサブネット内のEC2インスタンスがEFSにアクセスする仕組みを構築しています。そのためには**AZにおいてアクセスポイントとなる設定が必要不可欠**」・・・**マウントターゲットを通してAmazon EFSのファイルシステムにアクセスする。仕組みが必要**\n",
    "\n",
    "[**Amazon Aurora**]<br>\n",
    "- **Amazon Aurora MySQLデータベースはクラスター構成によって複数AZにまたがってボリュームを構成している** Amazon RDS MySQLデータベースに比較すると**AZ障害には強い構成**\n",
    "- しかしながら、**Auroraデータベースはさらに展開時にマルチAZ配置を有効化して、Auroraレプリカを複数アベイラビリティゾーンに展開することが可能** 。そうすることで、プライマリDBが配置されているアベイラビリティゾーン（それを構成するデータセンター）に障害が発生した場合は、**レプリカの１つをプライマリDBに昇格させることで、ダウンタイムを最小限にしてデータベース処理を継続させることができます。**\n",
    "- **Aurora DB クラスターは、最大で 15個の Aurora レプリカを配置することができます。**\n",
    "- Aurora レプリカは、AWS リージョン内で DB クラスターが使用している複数のアベイラビリティーゾーン間に分散して配置できます。このレプリカは**複数リージョンにも展開可能**です。プライマリDBに障害が発生した場合は、**１つのAurora レプリカをプライマリインスタンスに昇格**することができます。\n",
    "- **プライマリインスタンスのみでもデータを3つのAZにかけて6個のレプリケーションを作成**\n",
    "- **プライマリインスタンス障害は10分未満でサービスが回復**\n",
    "- **1つ以上のAuroraレプリカがある場合には、復旧時間は120秒未満であり多くの場合60秒未満で復元**\n",
    "- **プライマリのインスタンスに障害が発生すると、Auroraレプリカがプライマリに昇格しフェイルオーバーします。 フェイルオーバーの時間に関しては、多くの場合は  **60秒未満**とされています。数分程度という要件に対して特に問題なく機能することができます。**7\n",
    "- Amazon Aurora クラスターを構成してリードレプリカをマルチAZに展開します。さらに**Aurora グローバルデータベースを設定して、スタンバイ用DBを作成することができます。これによって、複数地域に跨ったデータベースのプライマリ/セカンダリ構成の運用を自動化することができます。**\n",
    "\n",
    "[**Amazon RDS DB**]<br>\n",
    "- **ElastiCacheをRDS前に設置することでキャッシュ処理によってDBのクエリ処理性能を向上させることが可能となります。**\n",
    "- **Amazon RDS DBインスタンスはリードレプリカを追加して、アプリケーションの読み込み負荷を分散することができる**、これは**非同期レプリケーション**です。\n",
    "- **Optimesd Write**が利用できるMySQLバージョンに変更して、Optimesd Writeを適用して書き込み処理を高速化することも可能。Amazon RDSのOptimesd Writeは書き込み処理を**最大50％向上**できるRDSの機能\n",
    "- マルチAZ構成で**RDSマスターともう一つのAZへはRDAスレーブを配置して同期レプリケーションによる自動フェイルオーバー機能も追加可能**\n",
    "- Amazon RDSをAuroraサーバレス MySQLに変更することでピーク時にオートスケーリングはされますが、**Auroraサーバレス はピーク以外の通常時においても一定のデータベース利用が発生しない、不規則なデータベース利用が発生する際に向いているDBタイプ**\n",
    "- (注意点)クエリ処理には向いていますが、**ログ解析には向いていません**。\n",
    "- （注意点）**RDSのAuto Scalingはデータ容量を増加させるだけ**つまり読み取りリクエストの増加等には関係ない。読み取り専用のリードレプリカの用意や単純にコストが高くなりますが、より高性能なインスタンスタイプに変更してスケールアップすることも最適な対応\n",
    "- Optimized Readsインスタンスを利用することで、ホストサーバーに物理的に接続されたローカル NVMe ベースの SSD ブロックレベルストレージに MySQL が生成する一時テーブルを配置することによりクエリ処理が高速化されます。これにより、ソート、ハッシュ集計、高負荷結合、共通テーブル式 (CTE) を含むクエリなど、一時テーブルを利用する複雑なクエリ処理についても、最大 50% 高速化されます。\n",
    "- **RDS Proxy**は、アプリケーションとRDSデータベースの間の仲介役として機能します。RDS Proxyは、必要となるデータベースへのコネクションプールを確立および管理し、アプリケーションからのデータベース接続を少なく抑える機能\n",
    "- (注意点)暗号化がされていないDBインスタンスはスナップショットも含めて、**後から暗号化を設定することができません。** したがって、**最新のDBスナップショットを使用してDBインスタンスを再作成**して、その際に暗号化を有効化することが必要です。DBインスタンスの暗号化を有効化することで、スナップショットを含めてすべてのデータが暗号化されるようになります。\n",
    "- **ElastiCacheはRDSなどのデータベース処理の高速処理化などで利用するべき構成**\n",
    "\n",
    "\n",
    "[**AWS Systems Manager**]<br>\n",
    "- **EC2インスタンスからAmazon RDS DBインスタンスにアクセスするために必要となるユーザー名とパスワードをセキュアに保存する目的のためにAWS Systems Manager パラメーターストアにパラメータを作成することができる**\n",
    "- 主に右記のような使い方：**パラメーターストアのパラメータに読み取りアクセスを許可するIAMポリシーを作成する。** このIAMポリシーを設定したIAMロールをAmazon EC2インスタンスに割り当てる。EC2インスタンスがパラメーターを取得して、Amazon RDS DBインスタンス認証を実施する。\n",
    "\n",
    "\n",
    "[**Amazon EventBridge**]<br>\n",
    "- アプリケーションの可用性の問題やリソースの変更などのシステムイベント発生時に自動的に実行されるワーク処理を作成する機能です。Amazon EventBridgeを利用することで、AWS Certificate Manager（ACM）のイベントをトリガーにしてアクションを実施することができます。その際は、AWS_ACM_RENEWAL_STATE_CHANGEを利用して、証明書が更新された、有効期限が切れている、または有効期限が切れる予定を利用したルールを設定できます。これによって、Amazon EventBridge が有効期限が切れる予定の証明書を検出して、**Amazon SNSと連携したアラーム通知を実施することが可能です。**\n",
    "- Amazon EventBridgeルールによって呼び出されるAWS Lambda関数で構成することも可能\n",
    "- AWSで発生する様々なイベントや外部のSaaSから発生するイベントをトリガーにして、さらに様々なAWSサービスと動作させることができるAWSリソース間をブリッジ（架け橋となるサービス）するサービスです。Amazon EventBridgeルールを設定することで、特定のイベント発生をトリガーにして、AWS Lambda関数などを呼び出すことができます。このシナリオでは、Amazon EventBridgeルールによって呼び出されるAWS Lambda関数を設定する際に、具体的なリソース間の権限設定方法が問われています。**Amazon EventBridgeによって他のAWSリソースを呼び出す際は、IAMポリシーによる権限付与がなされているなど、適切な権限設定が必要となります。**\n",
    "- Amazon EventBridgeでは、スケジュールに基づいて AWS Lambda 関数を実行するルールを設定できます。その際は、**lambda:InvokeFunction**をアクションに設定し、**EventBridge サービスプリンシパル (events.amazonaws.com) のアクセス許可を使用してルールを実行する**には、**add-permission コマンド**を使用します。\n",
    "\n",
    "\n",
    "[**Amazon EBS**]<br>\n",
    "- EBSのスループット最適化HDD\n",
    "  - 高いスループットを必要とするアクセス頻度の高いワークロード向けの低コストの HDD ボリューム.プロビジョンドIOPS SSDよりも低コストで実現  \n",
    "- EBSの汎用SSD\n",
    "   - 幅広いトランザクションワークロードに対応できる価格とパフォーマンスのバランスが取れた汎用 SSD ボリューム\n",
    "- EBSのプロビジョンドIOPS SSD\n",
    "   - イテンシーの影響が大きいトランザクションワークロード向けに設計された極めてパフォーマンスの高い SSD ボリューム。コストを度外視して、最も高いスループット性能を求められる際には正解\n",
    "- EBSのコールドHDD\n",
    "   - アクセス頻度の低いワークロード向けに設計された極めて低コストの HDD ボリューム\n",
    "- Amazon EBSは**Amazon S3 に格納するボリュームのポイントインタイムスナップショットを作成できます。** スナップショットを作成し、Amazon S3 へのコピーを完了すると 、1 つの AWS リージョンから別のリージョン、または同じリージョン内にスナップショットをコピーできます。その上で移動先リージョン内でEBSボリュームを複製することができます。\n",
    "- (補足)\n",
    " - **RAID0は複数のディスクを１台のディスクのように扱うため、「読み書きを高速化する構成」**\n",
    " - **RAID1はボリュームの冗長性を高めるため、RAID1では２つのボリュームを同時にミラーリングする。つまり「EBSボリュームにおいて不具合や破損が発生してもデータ消失しないようにデータ保持する仕組みが必要」を実現する。** スナップショットからの復元には、一定時間のシステム停止を要するため、ミラーリングに比較すると回復性が低い\n",
    " \n",
    "[**AWS Backup**]<br>\n",
    "- **様々なバックアップ処理を一元管理する仕組み**\n",
    "- **AWS BackupではAMIやスナップショットは別リージョンにコピーすることができます。**\n",
    "- 具体的には「AWS Backupを利用して、EBSのバックアップを取得して、対象EC2インスタンスのダウンに対して、新インスタンスを立上げてEBSボリュームを復元する。」ことで東京リージョンに障害が発生した場合に備えて、障害回復ソリューションを準備することが可能\n",
    "- こちらの対応も必須「AWS Backupを利用して、定期的にEC2インスタンスからAMIを取得して、別のリージョンにコピーするようにバックアッププランを作成する。」\n",
    "- \n",
    "[**DynamoDB**]<br>\n",
    "- DynamoDBを**オンデマンドに変更することで、一時的な負荷に対してキャパシティをスケーリングして高負荷に対応することが可能**<br>\n",
    "- (注意)**DynamoDBをマルチAZ構成で起動する機能はない** \n",
    "- オートスケーリングを利用したり、Amazon SQSを構成した方がコスト最適に対応。ただし「DynamoDBのオンデマンドモードを選択すると、DynamoDB は、前に到達したトラフィックレベルまで拡張または縮小して、ワークロードを即座に受け入れることができるようにします。したがって、**このモードにはAuto Scalingは必要ありません**」\n",
    "- アプリケーションの構成を変更することなく、DynamoDBのパフォーマンス効率を向上させるには**Amazon DynamoDB Accelrator（DAX）を利用して、DynamoDBテーブルにキャッシュレイヤーを追加**して高速処理を実施\n",
    "- **DynamoDBストリームでは、テーブル内の項目が変更された際の変更内容をストリームして通知する機能**\n",
    "   - **24時間を経過するとデータ変更履歴は消去される**\n",
    "   - \n",
    "- Lambda関数とAmazon EventBridgeと連携してDynamoDBをスケジュールに従ってモニタリングする。ことも可能\n",
    "- 上記CloudWatch EventsとLambda関数でイベント検知可能\n",
    "- DynamoDBテーブルは**利用される負荷が予測できる場合と、予測できない場合に応じて、オンデマンドモードとプロビジョニングモードの２つのキャパシティモードからキャパシティ設定を選択することができます。**\n",
    "- \n",
    "\n",
    "[**AWS WAF**]<br>\n",
    "- **AWS WAFのReferer制限によって直接にURLリンクを参照することを制限することができます。**\n",
    "- AWS WAF はウェブアプリケーションのファイアウォールであり、CloudFront に転送される HTTP および HTTPS リクエストのモニタリングや、コンテンツへのアクセスのコントロールを可能にします。指定された条件 (クエリ文字列の値や、リクエストの送信元 IP アドレスなど) に基づき、CloudFront はリクエストされたコンテンツまたは HTTP ステータスコード 403 (Forbidden) でリクエストに対応します。\n",
    "\n",
    "\n",
    "[**Route53**]<br>\n",
    "- Route53の**ヘルスチェックはトラフィックルーティングにおいてフェールオーバーを実施する際に利用する機能**これを利用しても、インスタンスにエラーが発生した場合にウェブサービスを実行するEC2インスタンスを再開することはできません。\n",
    "- Route53の**位置情報ルーティング**を構成して、特定地域からのアクセスを遮断する機能もある\n",
    "- （注意点）Route53の地理的近接性ルーティングには、特定地域からのアクセスを遮断する機能はありません。必要に応じてトラフィックをある場所のリソースから別の場所のリソースに移動する場合に使用します。\n",
    "- （補足）Amazon CloudFrontを利用した配信設定を行った上で、**AWS WAFを適用して、地理的制限を適用する。**といった設定も可能\n",
    "- 「現在利用しているpintor.comというドメインの静的ウェブサイトをAWS上で構築することになりました。この静的ウェブサイトにはサーバー側スクリプト処理は必要がないため、コスト最適に実装することが求められています。」・・・このようなケースの場合は、**Route53のパブリックホストゾーン内にpintor.comのドメイン設定して、エイリアスレコードに静的ウェブサイトのエンドポイントを指定する。**\n",
    "- Amazon Route 53 エイリアスレコード で、DNS 機能に Route 53 固有の拡張機能が追加されます。エイリアスレコードを使用すると、選択した AWS リソース (CloudFront ディストリビューションや Amazon S3 バケットなど) にトラフィックをルーティングできます。\n",
    "- **トランザクションデータを直接にDynamoDBテーブルに保存してDynamoDBトランザクション機能を利用します。DynamoDBトランザクション機能はDynamoDBテーブルへの書き込みなどのトランザクション発生時に特定の処理を実行させることができる機能**\n",
    "- (上記補足)　DynamoDBテーブルへのデータ書き込み時に機密性の高いデータを削除するアクションを設定して機密データを削除します。\n",
    "- DynamoDBストリーム はDynamoDB テーブル内の項目レベルの変更に関するシーケンスを時間順にキャプチャして保存する機能です。DynamoDBストリームによってDynamoDBテーブルに対するデータ変更が発生すると、Lambda関数などにリアルタイムに変更点をデータ連携するような構成が可能となります。\n",
    "- Route 53レコードは標準のDNSレコードを使用しますが、**CloudFrontなどのAWSリソースをRoute 53レコードに設定する場合はALIASレコードを利用することが必要となります。**  **ALIASレコードはRoute53においてELBなどのAWSリソースを設定するためのAWS独自のレコードです。** IPアドレスまたはドメイン名の代わりに、**ALIASレコードにはCloudFront、Elastic Beanstalk環境、ELB 、静的Webサイトとして設定されているAmazon S3バケットへのポインタ、または 同じホストゾーン内の別のRoute 53レコードを設定することができます。** \n",
    "\n",
    "これによって、DynamoDBテーブルにデータが保存された際に、そのストリームデータを他のアプリケーションに共有する仕組みをリアルタイムに実現することができます。\n",
    "\n",
    "[**Amazon Redshift**]<br>\n",
    "- **Amazon Redshift Spectrum**を使うことで、S3バケット上に保存されたファイルに対して直接、高度なクエリ処理を実行することが可能になります。Spectrumの実行には数千台までスケールできるインスタンスが用意されており、データセットがエクサバイトを超えても、高速なデータ取り出しと一貫したパフォーマンスを実現します。\n",
    "- **AWSのフルマネージドなデータウェアハウスサービス**で、**大規模なデータ分析を高速かつスケーラブルに行うことができます。** Redshiftは、特に**データの集計、分析、レポーティングに最適化されており、ビッグデータ環境での使用に向いています。**\n",
    "- **小規模利用からペタバイト単位の構造化データまで、複雑な分析クエリを実行でき、スケールアウトも容易に行うことができます。** Amazon Redshift データウェアハウスは、ノードと呼ばれるコンピューティングリソースのコレクションであり、これらはクラスターと呼ばれるグループを構成します。各クラスターは、1 つの Amazon Redshift エンジンを実行し、1 つ以上のデータベースを含みます。\n",
    "- RDSのマルチAZ配置と同様に複数AZに展開が可能\n",
    "- **大規模なトランザクションデータやログデータを集約して、高速にクエリを実行し、ビジネスインテリジェンスツール（例: Tableau、Power BI）で視覚的なレポートやダッシュボードを作成できます。**\n",
    "- (補足)　Redshiftはデータ解析に利用されるリレーショナルデータベース型のデータウェアハウスです。**ユーザー設定の保持と高速処理にはNoSQL型のDynamoDBの方が適しています。**\n",
    "\n",
    "\n",
    "[**AMI**]<br>\n",
    "- **複数のアカウント間でAMIを共有するには、AMIを別のアカウントと共有するための許可設定が必要となります。そのためには、AMIを第三者のAWSアカウントとのみ共有できるようにAMIのLaunchPermissionプロパティを変更することが必要です。**\n",
    "- (補足)AMIがKMSにより暗号化されている場合は、AMIのみを共有するだけでは第三者のAWSアカウントにおいてAMIを利用することができません。**AWS KMSのCMKを利用して暗号化されたAMIを利用するには、その暗号化に利用したCMKの権限を有していることが必要です。** したがって、**KMSのキーポリシーを変更して、第三者のAWSアカウントに対して、AMIの暗号化に利用したKMSキーを使用できる権限を付与します。**\n",
    "\n",
    "\n",
    "\n",
    "[**KMS**]<br>\n",
    "- **AMIはAmazon S3バケットにバックアップされており、AWS KMSのカスタマー管理キーを利用してスナップショットの暗号化を実施**\n",
    "- (補足)上記を用いてコンサルティング会社へオンプレミス環境から同社のEC2のAMIを用いて移行できる。\n",
    "  ←AMIをコンサルティング会社のAWSアカウントのみと共有できるようにAMIのLaunchPermissionプロパティを変更する。AWS KMSのキーポリシーを変更して、コンサルティング会社のAWSアカウントがKMSのキーを使用できるようにする。\n",
    "  \n",
    "  \n",
    "[**CloudFront**]<br>\n",
    "- CloudFrontは、コンテンツ配信ネットワーク（CDN）で、エンドユーザーに近いエッジロケーションからコンテンツを提供します。CloudFrontを使用することで、ウェブアプリケーションのレスポンス速度を向上させ、ユーザー体験を改善\n",
    "- Amazon CloudFrontの**フィールドレベル暗号化**を実施して、アップロード時のデータの暗号化を実施することで、ユーザーによるデータアップロード時の暗号化に対するセキュリティレイヤーを追加することができます。さらに、フィールドレベル暗号化では、特定のデータに特定のアプリケーションのみがアクセスできるように制限することができる\n",
    "- フィールドレベル暗号化により、ユーザーが機密情報をウェブサーバーに安全にアップロード\n",
    "- (注意点)**AWS KMSを適用して、アップロード時の暗号化を実施することはできません。**\n",
    "- CloudFrontディストリビューションを作成し、**オリジン（元となるサーバ）としてALBのDNS名を設定**します。これにより、CloudFrontはALBを通じてEC2インスタンスにリクエストをルーティングします。\n",
    "- 必要に応じて、キャッシュ設定や、SSL証明書（HTTPS通信を使用する場合）の設定を行います。\n",
    "- **エッジロケーションによるファイル圧縮処理を実施する。ことで経費削減が可能**\n",
    "   - ビューワーがリクエストヘッダーに Accept-Encoding: gzip を含めるようのリクエストした場合は、CloudFront が自動的に特定のタイプのファイルを圧縮\n",
    "   - CloudFront は各エッジロケーションでファイルを圧縮\n",
    "- **CloudFrontによるキャッシ保持期間を長くすることで経費削減が可能**\n",
    "- （注意点）Amazon EC2インスタンスとALBを利用して動画配信アプリケーションを構成している場合は、**Amazon CloudFrontディストリビューションをEC2インスタンスではなくALBに設定することが必要**\n",
    "- **CloudFrontにACMの証明書を連携して、HTTPS通信を有効化する。ことが可能**\n",
    "- AWS Transfer for SFTPを構成して、SFTPクライアントを使用して、ウェブコンテントをアップロードする。ことも可能\n",
    "\n",
    "[**AWS Transfer for SFTP**]<br>\n",
    "- AWS Transfer for SFTPを構成して、SFTPクライアントを使用して、ウェブコンテントをアップロードすることで、SFTPクライアントを使用したアップロード方式を設定できます。AWS Transfer Family は、AWS ストレージサービスとの間でファイルを送受信できる安全な転送サービスです。Amazon S3 と連携して、安全で高速なデータ転送を可能にします。\n",
    "\n",
    "\n",
    "[**AWS Global Accelerator**]<br>\n",
    "- パブリックアプリケーションの可用性、パフォーマンス、およびセキュリティの向上させるためのネットワークサービス\n",
    "- エッジでパケットをプロキシして最適なエンドポイントグループにルーティングするかを決めることで、TCP または UDP を利用した幅広いアプリケーションのパフォーマンスを向上\n",
    "\n",
    "[**NATゲートウェイ**]\n",
    "- NATインスタンスからNATゲートウェイに移行する決定は、**主に高帯域幅のトラフィック要求に対応するため** これを実現するには「NATインスタンスからNATゲートウェイに移行して、**NATゲートウェイをパブリックサブネットに設定**する。」\n",
    "- プライベートサブネットのルートテーブルにNATゲートウェイを設定する必要がある\n",
    "\n",
    "[**VPCエンドポイント**]\n",
    "- VPCエンドポイントはインターネットゲートウェイ、NATデバイス、VPN接続、またはAWS Direct Connect接続を必要とせずに、**VPCをPrivateLinkのサポート対象のAWSサービスとVPCエンドポイントサービスに接続**\n",
    "- VPC内のEC2インスタンスから、プライベートネットワークを経由して、VPC外に設定されるAmazon DynamoDBテーブルにアクセスする際は、**VPCにゲートウェイエンドポイントを構成**して、DynamoDBにルートを設定することが必要です。ゲートウェイエンドポイントは、VPC にインターネットゲートウェイや NAT デバイスを必要とせずに、Amazon S3 および DynamoDB への信頼性の高い接続を提供します。ゲートウェイであるため、ルートテーブルでルートを構成する必要があります。\n",
    "- **ゲートウェイエンドポイントは、「DynamoDBとS3のみに適用可能」**\n",
    "- (注意点)DynamoDBテーブル用のエンドポイントにはインターフェースエンドポイントは利用できません。ゲートウェイエンドポイントを利用\n",
    "- （注意点）**DynamoDBテーブル用のエンドポイントにはプライベートリンク接続は利用できません。**\n",
    "\n",
    "[**CloudFormationテンプレート**]<br>\n",
    "- **Egress: true で「アウトバウンド許可」**\n",
    "- AWS CloudFormationのテンプレートを利用して、AWSリソース設定を定義したJSON/YAMLファイルからプロビジョニングすることができます。 これによって、**テスト環境などのAWSリソース環境をテンプレート化して、自動で展開することが可能**\n",
    "\n",
    "[**CodePipeline**]<br>\n",
    "- CodeDeployやAmazon ECSなどのサービスをパイプラインとして設定することで、コードの開発からデプロイまでのステップをパイプライン化して、自動的に実行できるように制御することが可能\n",
    "- しかしながら、この**CodePipelineはインフラ環境のデプロイには利用できません。** インフラのデプロイ設定にはCloudFormationなどを利用する必要があります。\n",
    "\n",
    "[**ネットワークACL**]<br>\n",
    "- Network Access Control Listの略で、AWSにおけるVPC (Virtual Private Cloud) 内で使用される、**サブネットレベルのセキュリティ機能**の一つ\n",
    "- ネットワークACLは**ステートレス**です。つまり、リクエストのレスポンスに関する情報を保持せず、インバウンドとアウトバウンドのトラフィックを独立して扱います\n",
    "- **デフォルトのネットワークACLは、すべてのインバウンドおよびアウトバウンドトラフィックを許可**\n",
    "- （注意点）トラフィックやプロトコルタイプに応じて、トラフィック制御に利用される機能であり、**暗号化を達成する方法ではありません。**\n",
    "  \n",
    "[**SQS**]<br>\n",
    "- **遅延キューはキュー内のメッセージが配信されると、一定期間すべてのインスタンスからメッセージが見れなくなる設定** つまり、処理中のインスタンス以外のインスタンスへの可視性が問われているケースでは不向き\n",
    "- **ロングポーリングはSQSのキューに対してコンシューマーがメッセージを取得しに行った際に、一定時間メッセージを受領するまでの待機時間が設定されている状態のことです。** 一定時間ロングポーリングが設定されていると、**ポーリング回数を減らすことができます。**\n",
    "- 「ジョブの負荷に応じてインスタンスを増減すること。」に対応するには、**Amazon SQSキューサイズに応じて、EC2インスタンスを増減するようなAuto Scalingを構成**\n",
    "- **ショートポーリングはSQSのキューに対してコンシューマーがメッセージを取得しに行った際に、一定時間メッセージを受領するまでの待機時間にゼロが設定されている状態**\n",
    "- Amazon SQSを利用して、Amazon EC2インスタンスのコンポーネント間をメッセージを処理して、**並列処理**を実施するワークロードを構成が可能\n",
    "  - (補足)上記の処理がクラッシュした場合は、「もし**可視性タイムアウト**が設定されており有効期限を過ぎれば、別のEC2インスタンスでキューが取得される。」メッセージが受信された直後は、メッセージはキューに残ったままです。他のコンシューマーが同じメッセージを再処理しないように、Amazon SQS は可視性タイムアウトを設定しています。\n",
    "  - メッセージの**デフォルトの可視性タイムアウトは 30 秒です。最小値は 0 秒、最大スケールは 12 時間**\n",
    "  - 視性タイムアウトを設定するには、**ChangeMessageVisibility API**を使用して、適切な可視性タイムアウト値を設定することになります。これを利用して、**他のコンシューマーがメッセージを二重に取得しない待機時間を設定することで、Amazon RDSデータベースに重複データが保存されないようにします。**\n",
    "  - (注意点)**デフォルトでメッセージはデッドレターキューは設定されてない**\n",
    "  - AddPermission API適切な権限を付与するために利用する権限設定\n",
    "  - CreateQueue APIは新しいキューを作成するためのAPI設定\n",
    "  - ReceiveMessage APIは適切な待機時間を設定するための設定です。待機時間を設定するとすべてのコンシューマーがメッセージの取得を待機してしまいますので、処理が遅延\n",
    "- SQSとAuto Scalingを構成する際は**CloudWatchメトリックスに基づいてキューの処理量に応じたスケーリングを設定**\n",
    "- 完全マネージド型のメッセージキューイングサービスで、マイクロサービス、分散システム、およびサーバーレスアプリケーションの切り離しとスケーリングが可能\n",
    "- **負荷分散が可能**\n",
    "- 送信順序を守られることが要件の場合は、「**FIFOキューを利用**」\n",
    "- **メッセージグループID**を利用することで同じグループのメッセージはまとめて送信されるようにFIFOキューを調整することができます。\n",
    "- 優先度の高いキューと優先度の低いキューを用意します。クライアント側ではジョブの優先度に応じて、どちらのキューに登録するか決めます。\n",
    "- **Amazon SQSではキューに対して優先度を設定することができます。それによって、優先的に処理されるキューとそうではないキューとに振り分けることが可能**\n",
    "\n",
    "[**Amazon SNS**]<br>\n",
    "- SNS はブロードキャスト（1対多の配信）が得意\n",
    "  → **1 つの SNS トピックにメッセージを送ると、複数の SQS キューに同時に送信可能**\n",
    "- **SQS はメッセージの蓄積や遅延処理が得意**\n",
    "  → SNS から送信されたメッセージを蓄積し、後で安全に処理できる\n",
    "- イベント通知を起点としたトリガーとして利用し、実処理はSQSに連携してポーリングするというのが標準的なAWSでのアーキテクチャ構成\n",
    "- **コンポーネント処理間の連携を確実に実行するには並列処理による負荷分散が可能なAmazon SQSが最適**\n",
    "- (注意点)　Amazon SNSにおいてFIFOトピックを利用して、メッセージの送信順序を守ることができますが、**グループ化する仕組みはありません。**\n",
    "- Amazon SNSトピックを作成して、イベント発生をトリガーにしてメッセージを配信する。**Amazon SQSキューをSNSトピックのサブスクライバー**として設定する。さらに、そのキューからメッセージを取得するAWS Lambda関数を設定する。・・・ここまですることで「例えばEコマースの企業であれば注文が発生した時点をトリガーにして、異なるタスク処理を実施する複数のコンシューマーグループにデータを送信して、それぞれのタスクを処理をすること」\n",
    "   - (注意点)Amazon SQS FIFOキューを作成して、メッセージを保通知する場合は、非同期通信となるため、複数のコンシューマーに同期的に通知を実施することができません。\n",
    "\n",
    "\n",
    "[**Amazon Kinesis Data Streams**]<br>\n",
    "- デバイスなどから送られる大量のストリーミングデータを**リアルタイムに収集、処理して別のサービスに送信するサービス**\n",
    "- Amazon Kinesis Data Streamsを使用してデータを収集するように、**KCLを利用してデバイスデータ処理用のコンシューマーアプリケーションを作成することが可能**\n",
    "  - (ex)毎日100GB以上のストリームデータを取得して、集計するリアルタイム処理用のワークロードを構築する\n",
    "  - KCL は、分散コンピューティングに関連する複雑なタスクの多くを処理することで、Kinesis データストリームからデータを消費および処理するためのライブラリを提供\n",
    "  - **EC2インスタンスなどにデプロイして利用。** ワーカーがシャード数に応じて、ライフサイクル管理(生成/終了)を実施\n",
    "  - KCLは各アプリケーションインスタンスに対応するライブラリです。KCLは分散コンピューティングに関連する複雑なタスクの多くを処理することで、Kinesis データストリームからデータを消費および処理することができます。複数のコンシューマーアプリケーションインスタンス間での負荷分散、コンシューマーアプリケーションインスタンスの障害に対する応答、処理済みのレコードのチェックポイント作成、リシャーディングへの対応などが実行可能です。\n",
    "  - (ex)KCLを利用してデータ処理アプリケーションを構築して、Amazon Kinesis Data Streamsに対してセッションごとにWebクリックをストリーミング処理する。ことも可能\n",
    "- **ログ解析には向いていません。**\n",
    "- KDGはテストデータを簡単に送信可能\n",
    "\n",
    "[**Amazon Kinesis Data Kinesis Firehose**]<br>\n",
    "- 大量のストリーミングデータを取得して、Lambda関数によってETL処理をしつつ、RedShiftやS3などのストレージやデータベースに配信するサービス\n",
    "- （注意点）Amazon Kinesis Data Firehoseによるストリーミングデータのデータ配信処理は**60秒ごとにまとめて実施されるため、リアルタイムデータ処理には向いていません。**\n",
    "- (注意点)**画像データをAmazon S3バケットに配信することはできません。**\n",
    "- ストリームデータを変換したり、ストレージやDBに配信するサービスです。Amazon Kinesis Data Firehoseを利用して、データをAmazon S3データレイクに送信することができます。\n",
    "\n",
    "[**API Gateway**]<br>\n",
    "- Amazon API GatewayはAPIへのアクセスを IAM のアクセス権限によって制御することができます。\n",
    "- API Gatewayに特定のアカウントを指定したスロットリングを追加することで、特定アカウントのユーザーからのアクセスが過多になっていた場合に、そのユーザーからのAPIリクエストを制限することができます。\n",
    "- 「未承認ユーザーからのリクエストをブロックする」には？\n",
    "  - **特定ユーザーのみに付与されるAPIキーを使用する使用量プランを作成する**\n",
    "  - **Amazon API Gatewayを利用してプライベートAPIに設定する。**\n",
    "  - \n",
    "- (補足)API Gatewayに対するAPIリクエストは、IAMロールなどの権限がない外部システムやユーザーからも実行が可能です。\n",
    "\n",
    "[**Lambda**]<br>\n",
    "- [Lambda関数を使ってSQSにメッセージを送信するために必要な設定]は？<br>\n",
    "　→IAMロールをLambda関数に設定して、Amazon SQSへのアクセスを可能にする。<br>\n",
    "  他のAWSリソースと連携するLambdaファンクションを作成する際は、IAMによる実行ロールをLambdaファンクションに設定してアクセス権限を付与することが必要です。 このIAMロールに付与されたアクセス権限によって、Lambdaファンクションが操作できるAWSリソースの範囲が決まります。\n",
    "- API Gatewayを省略してパブリックに公開するAPIや、簡易な認証実装でも差し支えの無いAPIを AWSLambdaで実装することができます。(Lambdaの関数URLをパブリックに設定する。)\n",
    "\n",
    "[**Amazon SWF**]<br>\n",
    "クラウドのワークフロー管理アプリケーションで、複数マシン間でアプリケーションを連携させるためのツールを開発者に提供\n",
    "\n",
    "[**Amazon EMR**]<br>\n",
    "- Apache Sparkなどのソフトウェアを構成して、デバイスなどから送られる大量のストリーミングデータをリアルタイムに収集、分析するサービス\n",
    "- Amazon EMRは、動的にスケーラブルなAmazon EC2インスタンス全体で膨大な量のデータ処理を簡単、高速、そして費用対効果の高いものにするマネージド**Hadoopフレームワーク**を提供します.\n",
    "- Webインデックス作成、データマイニング、ログファイル分析、機械学習にむいてる\n",
    "\n",
    "[**Amazon Inspector**]<br>\n",
    "- 自動化されたセキュリティ評価サービスで、AWS にデプロイしたアプリケーションのセキュリティとコンプライアンスを向上させることができます。EC2インスタンスにエージェントをインストールして、そこにホストされたアプリケーションの意図しないネットワークエクスポージャーなどの脆弱性を検知\n",
    "\n",
    "[**Amazon GuardDuty**]<br>\n",
    "- Amazon S3 ログ、CloudTrail 管理イベントログ、DNS ログ、Amazon EBS ボリュームデータ、Kubernetes Audit Logs、Amazon VPC フローログ、RDS ログインアクティビティの AWS CloudTrail データイベントなどのデータソースを分析して、DDoS攻撃以外の様々なネットワークへの不正アクセスを自動的に検知\n",
    "- AWS Shield はELBやAmazon CloudFront にRoute53と連携して利用されるサービスとなっています。Amazon CloudFront にAWS Shieldを組み合わせて、Web アプリケーションへの DDoS 攻撃に対して最適な防御壁を設定することができます。\n",
    "\n",
    "[**AWS Compute Optimize**]<br>\n",
    "- EC2インスタンスタイプ、Amazon Elastic Block Store (EBS) ボリューム、AWS Lambda 関数の 3 種類の AWS リソースの過剰プロビジョニングや過小プロビジョニングなどの利用状況に基づいて、コスト最適化のアドバイスを実施\n",
    "\n",
    "[**Amazon ALB**]<br>\n",
    "- ALBは**レイヤー7の負荷分散を行い、アプリケーションレベルでのルーティングや、ヘルスチェックをサポート**します。\n",
    "\n",
    "[**AWS Data Pipeline**]<br>\n",
    "- AWSサービス間のデータ転送や変換処理に利用されるサービスであり、ストリームデータを取得・変換する際には利用できません。AWS Data Pipeline は保存場所にあるデータに定期的にアクセスし、データの変換と処理を行い、その結果を Amazon S3、Amazon RDS、Amazon DynamoDB、Amazon EMRなどのAWS サービスに効率的に転送\n",
    "\n",
    "[**AWS Systems Manager**]<br>\n",
    "- **AWS Systems Manager はオンプレミス環境とAWS環境のインフラストラクチャの利用状況を可視化し、制御するための統合運用サービス**\n",
    "\n",
    "\n",
    "\n",
    "[**AWS Fargate**] <br>\n",
    "- AWS Fargateは、Amazon Web Services（AWS）が提供する**サーバーレスコンテナサービス**で、コンテナの管理やインフラのプロビジョニングを自動化することができます。Fargateを使用すると、コンテナの実行に必要なサーバーやインスタンスを管理することなく、アプリケーションを展開できる\n",
    "- Fargateは、コンテナの実行に必要なサーバーリソースを自動で割り当て、スケールします。**開発者はコンテナの実行に必要なリソース（CPU、メモリなど）を指定するだけで、インフラの設定や管理を行う必要はありません。**\n",
    "- Fargateは、コンテナの負荷に応じてリソースをスケールできます。\n",
    "- AWS Fargateは、Amazon ECS（Elastic Container Service） や Amazon EKS（Elastic Kubernetes Service） で動作します。これにより、Fargateを使ってコンテナ化されたアプリケーションをECSやEKSの管理下で簡単にデプロイできます。\n",
    "- Amazon ECSクラスターをAWS Fargateを起動タイプを利用してプロビジョニングすることで要件を達成することができます。**コンテナをFargateタスクにデプロイすることで、コンピューティングリソースをサーバレスに起動・スケールすることができるため、コンテナオーケストレーションの管理オーバーヘッドをなるべく抑制しつつ、タスクを利用したマイクロサービスを構成することができます。**\n",
    "\n",
    "[**Amazon ECS**]<br>\n",
    "- Amazon ECS は、コンテナ化されたアプリケーションを簡単にデプロイ、管理、スケーリングすることができるフルマネージド型のコンテナオーケストレーションサービスです。**Amazon ECS はコンテナ構成時に、EC2インスタンスをコンテナに利用するEC2起動モードと、サーバレスコンピューティングサービスであるFargate起動モードを選択することができます。**\n",
    "- Amazon ECSコンテナから他のAWSリソースにアクセスをする際は、タスクに対して、そのサービスへのアクセス許可が設定されたIAMポリシーを付与したIAMロールを設定することが必要\n",
    " - タスク IAM ロールはtaskRoleArn API オペレーションによって定義できます。\n",
    " - (注意点)　**IAMロールはAmazon ECS コンテナインスタンスに設定するのではなく、タスクに設定する必要があります。**\n",
    " - (注意点) タスク実行ロールは、ECS コンテナエージェントがタスクを実行（起動）するときに必要なロールを定義するものであり、コンテナ自体の動作権限を付与するものです。タスクに対して、その他のAWSサービスへのアクセス許可をするためのロールではありません。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e83821a0-305c-471b-8041-f75a6629880d",
   "metadata": {},
   "source": [
    "### 知見,アーキテクチャ設計ユースケース\n",
    "[**CloudFrontとHTTP領域**]<br>\n",
    "CloudFrontを利用しグローバルにコンテンツを配信することを考えた場合「言語処理」\n",
    "を例えば以下のようにHTTP領域にて展開する方法もある。パラメータをこれで送ることが可能\n",
    "- http://pintor.cloudfront.net/index?language=jp\n",
    "- http://pintor.cloudfront.net/index?language=en<br>\n",
    "この場合は「クエリ文字列パラメーター値に基づくキャッシュ設定を行うことでHTTPフィールド内の言語表示に基づいて配信方法を切り替えること」で実現可能\n",
    "\n",
    "(補足)<br>\n",
    "クエリ文字列（URLパラメーター）とは、サーバーに情報を送るためにURLの末尾につけ足す文字列（変数）のことです。「?」をURLの末尾につけ、その次に「パラメーター＝値」をつけ、複数のパラメーターをつけたい場合は「&」を使用します。この形式で、サーバーに送信したいデータをURLにつけ加えることが可能\n",
    "\n",
    "[**SQSによるマイクロサービス化されたコンポーネントとの連携処理**]<br>\n",
    "マイクロサービス化されたコンポーネント間の処理を連携する際は、Amazon SQSを利用したポーリング処理が最適となります。\n",
    "例えば：Amazon ECSを活用してマイクロサービス型のアプリケーションを構築しています。 このアプリケーションのアーキテクチャでは、マイクロサービス１とマイクロサービス２に分割し、マイクロサービス１の処理後にマイクロサービス２に処理が引き渡されます。\n",
    "]\n",
    "\n",
    "[**IoTセンサーに基づいたデータ分析**]<br>\n",
    "上記のようなケースではまさに「Amazon Kinesis Data Streams」を活用すべき。Amazon Kinesis Data Firehose経由でAmazon S3バケットに送信。<br>\n",
    "注意点として「デフォルトでは、データレコードがAmazon Kinesis Data Streamsに投入されてから24時間以内までアクセスできるように設定されている。」\n",
    "\n",
    "[**ELBから結合されたログファイルを分析できるようにアプリケーションを構築**]<br>\n",
    "Amazon S3に対してELBのログファイルを収集し、Amazon EMRでログ解析を実施する方法が考えられる。\n",
    "ログファイルの収集場所としてはAmazon S3が適切。このログファイル分析には大量データ解析が可能なパフォーマンスが必要\n",
    "\n",
    "[**エッジ処理とは？**]<br>\n",
    "「エッジ処理」とは、CloudFrontエッジロケーションで実行される処理のことを指します。エッジロケーションでは、リクエストの処理が行われる際、以下のような処理が実施されることがあります：\n",
    "- コンテンツキャッシュ: CloudFrontエッジサーバーが、ウェブサイトの静的コンテンツ（HTML、画像、動画、CSS、JavaScriptなど）をキャッシュし、リクエストがあるたびに高速に返します。これにより、リクエスト元のサーバー（オリジンサーバー）への負荷を軽減し、応答速度を向上させます。\n",
    "- リクエスト/レスポンスのカスタマイズ: CloudFrontは、**Lambda@Edge**という機能を使って、リクエストやレスポンスに対してカスタマイズを行うこともできます。これにより、リダイレクトや認証、リクエストヘッダーの変更、レスポンス内容の変更など、エッジでの処理を行えます。\n",
    "- 動的コンテンツの処理: 一部の動的コンテンツ（例えば、ユーザーごとに異なるデータを提供するAPIレスポンスなど）も、エッジサーバーで処理され、オリジンサーバーへのアクセスが減少します。これにより、コンテンツ配信が迅速になります。\n",
    "\n",
    "[**データベース障害を抑止するソリューションとコスト最小限で１つのデータセンターに依存した構成**]<br>\n",
    "- **データを同期的にレプリケートするようにマルチAZ配置を有効にしたAmazon RDS DBインスタンスを構成**する。\n",
    "\n",
    "[**Amazon S3に保存されているデータにアクセスする必要がありますが、 トラフィックはインターネットを通過できない場合は？**]<br>\n",
    "- **VPCのプライベートサブネットにインターフェースエンドポイントを設定**して、IPアドレス経由でアクセスする。\n",
    "\n",
    "[**EC2インスタンス側の暗号化はどうやるの？**]<br>\n",
    "- 利用している**EBSボリュームの有効化**を実施する必要があります。Amazon EBSボリュームは**AWS KMSと連携**して暗号化キーを利用して、容易にデータを暗号化することができます。\n",
    "\n",
    "[**Amazon S3の保存データを保護するには？**]<br>\n",
    "- サーバーサイド暗号化を使用つまり、**オブジェクトをデータセンターのディスクに保存する前にAmazon S3で暗号化**し、オブジェクトを**ダウンロードするときに復号化**するように要求します。S3のデフォルト暗号化を有効化する際に、**SSE-S3**と**SSE-KMS**のどちらかの暗号化形式を選択\n",
    "- クライアントサイド暗号化を使用つまり、データをクライアントサイドで暗号化し、暗号化されたデータをAmazon S3にアップロードできます。この場合は、暗号化プロセス、暗号化キー、および関連ツールを管理\n",
    "\n",
    "[**SSL/TLS証明書を用いた基礎**]<br>\n",
    "- セキュリティ要件として、保管中およびAWSに転送中のデータを保護するための方策の場合は、SL/TLS証明書を利用して、HTTPSプロトコルを利用した通信を実施しています。を使用するロードバランサ（SSLオフロードとも呼ばれる）を作成できます。この機能により、ロードバランサーとHTTPSセッションを開始するクライアント間、およびロードバランサーとEC2インスタンス間の接続のトラフィック暗号化が有効\n",
    "\n",
    "[**S3バケットのコンテンツをCloudFrontディストリビューションから配信する際に、S3 オブジェクトURLに直接アクセスできないようにしてから、WAFを適用することが求められるケースでは？**]<br>\n",
    "- Amazon CloudFront側でオリジンアクセスアイデンティティ（OAI）またはオリジンアクセスコントロール (OAC) を作成し、そのOAIまたはOACにのみ読み取りアクセスを許可するようにS3バケットポリシーを設定\n",
    "- こうすることで、OAIまたはOACのみがS3バケットにアクセスできる構成となり、CloudFrontはOAIまたはOACを介してS3バケットのコンテンツにアクセスして配信処理を行います。\n",
    "\n",
    "\n",
    "[**既存のEC2インスタンスからAmazon RDS DBインスタンスへのアクセスがIPアドレスを経由して設定されています。Auto Scalingグループから新しいインスタンスが起動する際に、データ処理時にエラーが発生どうする？**]<br>\n",
    "- Amazon RDSのセキュリティグループにおいて、EC2インスタンスに設定されたセキュリティグループIDをターゲットにして、3306ポート番号のアクセス許可を設定する。Auto Scalingグループで選択する起動テンプレート設定で同じセキュリティグループを利用する。\n",
    "\n",
    "[**DB構成を変更して、DBインスタンスの高可用性、読み取りワークロードの容量の増加、および書き込みレイテンシーの低減を最大限に達成するには？**]<br>\n",
    "- 既存のデータベースを**Amazon RDS マルチAZクラスター配置に変更する。** 書き込みリクエストはプライマリのDBインスタンスで処理して、読み込みリクエストはリードレプリカで処理する。\n",
    "\n",
    "[**アプリケーションに対するHTTPエラーを検出して、これらのエラーが発生した場合、ウェブサービスを実行するEC2インスタンスを自動で再開する必要があります。この要件を満たすためには？**]<br>\n",
    "-**ALBの異常なターゲット数をモニタリングするAmazon CloudWatchアラームを作成する。アラームがALARM状態になると異常状態のインスタンスを置換するように、Auto Scalingアクションを構成する**\n",
    "- **Unhealthyhostcountのメトリクス**をモニタリングするAmazon CloudWatchアラームを作成\n",
    "\n",
    "[**起動時にEC2インスタンスがソフトウェアと共にプレインストールされるように設定する必要があります。**]<br>\n",
    "- ユーザーデータにインストール用のBashスクリプトを加える。またはゴールデンイメージを作成して、起動設定を設定する。\n",
    "\n",
    "\n",
    "[**特定の期間に高負荷が予想されており、かつ、一定の処理負荷になった場合にもスケーリングを自動で実行すること設定はどうする？**]<br>\n",
    " - 動的オートスケーリングの**ターゲッツ追跡スケーリングポリシー**によって、一定のCPU利用に応じてスケーリングを実行\n",
    " - あらかじめスケーリング実施期間を設定することが可能となります。**スケジューリングによるオートスケーリングを設定**することで、特定の期間にスケーリングを実行\n",
    " - (注意点)ステップスケーリングポリシーは動的スケーリングにおいて、スケールさせるインスタンス数を段階的に増やすステップなのでこのケースでは不適切\n",
    "\n",
    "\n",
    "[**S3による複数ドメインを利用した静的ウェブサイトの構築におけるAjax通信の設定は？**]<br>\n",
    "- **Amazon S3バケットのCross-Origin Resource Sharing (CORS)を有効化する。ことで実現が可能**\n",
    "- CORSは、特定のドメインにロードされたクライアントウェブアプリケーションが異なるドメイン内のリソースと通信する方法を定義\n",
    "\n",
    "[**複数リージョンに冗長化された構成が必要となったため、EC2インスタンスに接続されているEBSボリュームを東京リージョンから、別のリージョンに移動させたい・・どう構築する？**]<br>\n",
    "- 対象のEBSのスナップショットを作成して別リージョンでEBSボリュームを複製する。\n",
    "\n",
    "\n",
    "[**Amazon RDS DBインスタンスを利用し書き込み処理と読み取り処理を分割することが必要です。この要件を満たすために、最も効果的なDB構成は？**]<br>\n",
    "- プライマリDBインスタンスと同じコンピューティングリソースを利用して、リードレプリカを追加する。書き込みリクエストはプライマリのDBインスタンスで処理して、読み込みリクエストはリードレプリカで処理することが可能\n",
    "\n",
    "[**今後数年は利用するアプリケーションですが夜間や休日はあまり使用されないため、負荷が一定ですが、不定期に日中は負荷が急増する、、アプリケーションの可用性に影響を与えることなく、EC2インスタンスのコストを削減するには？**]<br>\n",
    "- **通常処理に必要なベースラインキャパシティにはリザーブドインスタンスを使用する。アプリケーションの負荷増加に対してはスポットインスタンスを利用**\n",
    "   - ワークロード全体に対してリザーブドインスタンスを使用してしまうと、負荷急増時のキャパシティまで考慮して最大数を予約購入することになるため、コスト最適になりません。\n",
    "   - （補足）１年１カ月利用していたインスタンス等の場合は、３年間前払いしていることを意味しています。そのため、リザーブドインスタンスをただシャットダウンするだけでは前払い分を損してしまいます。したがって、マーケットプレイスで販売することが必要。またその際に「**EBSボリュームのスナップショットを取得しインスタンスを停止することで、データのみを保持することができます。**」\n",
    "\n",
    "[**HTTPトラフィックとHTTPSトラフィックを別々に処理するALBのリクエストがすべてHTTPSを使用するように構成しなおす方法は？**]<br>\n",
    "- Application Load Balancer のリスナールールを使用して、HTTP リクエストを HTTPS にリダイレクトする設定を利用します。ALBのリスナー設定において、[リダイレクト先] として port 443 （デフォルトのポート以外を使用する場合はその値）を指定することで、HTTP リクエストを HTTPS にリダイレクトされるように設定すること\n",
    "\n",
    "[**S3バケットを利用したコンテンツ共有の仕組みを構築しています。このコンテンツ共有を利用するユーザーからのアクセスに限定する必要があり、インスタンスのIPアドレスからのみオブジェクトにアクセスできるように設定することが要件となっています。この要件を達成するには？**]<br>\n",
    "- **Amazon CloudFrontにおいてOAIを作成して、Amazon S3バケットポリシーにOAIのみにアクセス許可を設定**\n",
    "- **CloudFrontを設定してWAFの IP ホワイトリストを実施する。**\n",
    "- (補足) WAFのWEB ACLによる制御をReferer制限と呼びます。\n",
    "\n",
    "[**単一のデータセンター障害に停止することなく、アプリケーション処理を継続できる構成は？**]<br>\n",
    "- 2つのアベイラビリティゾーンそれぞれにまたがって、２つのEC2インスタンスを起動して、それぞれをELBターゲットグループに設定する。その上で、ターゲットグループに対して２つのアベイラビリティゾーンに指定したAuto Scalingグループを構成する。\n",
    "\n",
    "[**EC2インスタンスの状態の変更発生などをモニタリングする方法を模索しています。要件としてはインスタンスの状態を監視し、各状態の変化が発生した時点をトリガーとして、データベースに変更状況を記録するにはどうする？**]<br>\n",
    "- Amazon EventBridgeを利用してインスタンスの状態変化をトリガーにして、アクションを設定する。\n",
    "- Lambdaファンクションを利用して状態記録をDynamoDBに蓄積する。\n",
    "\n",
    "[**アプリケーションのスタックを複数のマイクロサービスに分割して疎結合化すること、その際は、コンテナを利用してマイクロサービスを作成するが運用要件として、AWS上でコンテナ用コンピュートリソースの構成管理が必要ないこと、この要件を満たすには？**]<br>\n",
    "- **Amazon ECSクラスターをFargate起動モードでプロビジョニングする。コンテナにFargateタスクをデプロイする。**\n",
    "- (補足) AWSではDocker形式のアプリケーション開発環境を提供するAmazon ECSと、kubernetesと呼ばれる形式のコンテナー仮想化を実現するAmazon EKSの２つのサービスが利用可能です。その中で利用できるコンピューティングエンジンにはサーバータイプのEC2起動タイプとサーバレスで実行可能なFargate起動タイプの２種類から選択することができます。\n",
    "- (補足)　AWS Fargateはインスタンスのタイプやサイズなどのプロビジョニング設定を自動で構成してくれるため、Dockerコンテナのコンピューティング設定や運用管理が自動化できます。\n",
    "- (補足)　**Amazon ECRはDockerイメージというファイルを保存するサービス**です。イメージはDockerコンテナ構成を保存して、再利用することができます。\n",
    "\n",
    "\n",
    "[**LambdaファンクションがDynamoDBテーブルを操作できるように権限を設定する必要,どのように権限を設定する？**]<br>\n",
    "- Lambdaファンクションに**IAMロールを設定**してDynamoDBへのアクセスを許可する。\n",
    "\n",
    "[**オンプレミス環境上の静的ウェブサイトをAWSに移行することを決定、できるだけ迅速に世界中のユーザーが閲覧できる必要があり、コスト最適なアーキテクチャが求められている、何を実施するべき？**]<br>\n",
    "- 静的WEBサイトをAmazon S3から配信するように静的ウェブホスティングをS3バケットに構成する。Amazon CloudFrontを構成し、S3バケットをオリジンとして設定する。\n",
    "- この静的WEBホスティングを有効化したS3バケットをオリジンサーバーとしてCloudFrontに構成します。これによって、エッジロケーションを介して、静的WEBサイトのコンテンツをグローバルに高速に配信することができます。\n",
    "- （補足）静的WEBホスティングを設定したS3バケットに対してRoute53を構成して、ドメインを設定することができます。しかしながら、グローバルなコンテンツ配信を最適化する場合はCloudFrontを利用する必要があります。\n",
    "\n",
    "[**SNSとSQSを組み合わせたアーキテクチャの仕組み**]<br>\n",
    "(設定方法)\n",
    "1. Amazon SNS トピックを作成\n",
    "「トピック」とは、メッセージを送信するための ブロードキャストチャンネル のようなもの\n",
    "例: OrderEventsTopic（注文関連のイベント通知トピック）\n",
    "2. Amazon SQS キューを作成\n",
    "キュー とは、SNS から送信されたメッセージを受け取り、一時的に蓄積するもの\n",
    "例: OrderProcessingQueue（注文処理用の SQS キュー）\n",
    "3. SQS キューを SNS トピックにサブスクライブ\n",
    "OrderProcessingQueue を OrderEventsTopic にサブスクライブ（登録）\n",
    "SNS にメッセージが送られると、自動的に SQS にもメッセージが送信される\n",
    "4. 必要なら IAM ポリシーを設定\n",
    "SQS キューが SNS からのメッセージを受け取れるように アクセス許可（IAM ポリシー） を設定\n",
    "\n",
    "※上記を例に以下のような設定も可能<br>\n",
    "(ex)ある会社では、AWSを利用した発注管理用のアプリケーションを設計しています。このアプリケーションを利用してユーザーが発注すると、12時間以内に処理される必要があります。発注内容は多岐にわたるため、注文内容を分類して管理することも必要です。<br>\n",
    "費用対効果と運用効率を最大限にしつつ、これらの要件を満たすソリューションはどれでしょうか。<br>\n",
    "(アーキテクチャ例)<br>\n",
    "「Amazon SNSトピックを１つ作成して、Amazon SQSキューからこのSNSトピックにサブスクライブする。SNSトピックへのフィルターを設定して注文内容に応じて適切なSQSキューに適切なメッセージが送られるようにメッセージを分割する。注文に応じたSQSキューからメッセージを受信するようにバックエンドサーバーを設定する。」<br>\n",
    "\n",
    "- (注意点)　Amazon SQSキューはあくまでもメッセージの配信機能を提供しているだけです。したがって、Amazon SQSキューだけではDynamoDBテーブルへの書込処理機能を実現できません。SQSキューからメッセージをポーリングして、Lambda関数がデータ処理を実行する必要があります。\n",
    "\n",
    "\n",
    "[**WEBアプリケーションの提供ベンダーが使用する資格情報は、そのベンダーのみが利用できるように制限することが必要です。したがって、第三者による目的外利用ができない形式で権限を付与することが必須、この要件を満たすには？**]<br>\n",
    "- **外部WEBアプリケーションが必要とする権限のみに限定したアクセス権限を付与したIAMポリシーを設定**して、それに**基づいたクロスアカウントアクセスが可能となるIAMロールを作成**し、外部WEBアプリケーションに設定する。\n",
    "- (補足)上記は、「サードパーティのベンダーのみが利用できるように制限する方式でのアクセス制御が必要.\n",
    "  つまり、**クロスアカウントアクセスによって外部ベンダーに適切なアクセス権限を委譲する方法**が問われています。」\n",
    "\n",
    "\n",
    "[**1つのAZがダウンした場合でもアプリケーションが決して停止しないことが要件であるため、AZが１つ停止した直後でも（Auto Scalingが実行される前の段階でも）100％の可用性を維持する必要がある。どうする？**]<br>\n",
    "- オプションの中で、1つのAZが利用できなくなった場合でもEC2インスタンスのピークロードが、 100％の処理を維持できる設定を選ぶことになります。\n",
    "- 通常はAuto Scalingが実行されてから、実際に負荷が軽減されるまでに数分から数十分程度のタイムラグが発生します。そのため、 1つのAZが利用できなくなり、かつAuto Scalingが残りのAZで新しいインスタンスを起動できない障害が発生しても、アプリケーションが完全に利用可能な状態を維持できるようにするためには、Auto Scalingの新規起動が間に合わない場合や失敗した場合でも100％を維持できるEC2インスタンスのマルチAZ配置が必要となります。\n",
    "\n",
    "\n",
    "[**現在のDB認証方式が安全ではないため、セキュリティ設定を向上させるように依頼されました。ユーザー認証情報を自動的にローテーションして、WEBサーバーによるデータベース接続をセキュアにする必要があります。どうする？**]<br>\n",
    "- **ユーザー認証情報をAWS Secrets Managerに保存する。IAMアクセス許可を付与して、EC2インスタンスによるAWS Secrets Managerへのアクセスを許可する。**\n",
    "- (補足)**AWS Secrets Managerはデータベースやその他のサービスの認証情報を安全に暗号化してシークレットとして保存・取得する仕組みを提供します。** Secrets Manager にデータベースのユーザー認証情報を保存することで、WEBサーバーがSecrets Manager から認証情報を取得して、安全にデータベースに接続することが可能となります。\n",
    "- **他のAWSリソースがSecrets Manager内の情報にアクセスするためには、IAMポリシーによる許可設定が必要となります。** したがって、IAMロールによってEC2インスタンスによるAWS Secrets Managerへのアクセスを許可することが必要\n",
    "- データベース認証情報、アプリケーション認証情報、OAuthトークン、API キー、およびその他のシークレットを保存して管理することができます。ライフサイクル管理機能を通じて、シークレットの管理、取得、ローテーションすることができます。\n",
    "\n",
    "[**ELBにAWS Certificate Manager（ACM）にインポートされた証明書を設定して、トラフィック通信をHTTPSにしました。さらに、証明書管理のために、同社のセキュリティチームが各証明書の有効期限の10日前に通知されるように設定することが求められています。どうする？**]<br>\n",
    "- **ACM証明書の有効期限をチェックするAmazon EventBridgeルールを作成**して、10日以内に有効期限切れになる証明書がある場合は、**Amazon SNS通知を実施**する。\n",
    "- \n",
    "\n",
    "[**Lambda関数側で取得したデータがデータベース接続に失敗した際にも失われないように処理中に保持される仕組みは？**]<br>\n",
    "- これを解決するために、Lambda関数が取得した顧客データをAmazon SQSキューに保存して、別のLambda関数がこのキューをポーリングして、顧客データをAuroraデータベースに保存する構成とすることで、処理中のデータ喪失を防ぐことができます。\n",
    "\n",
    "[**どんなユーザーであっても新しいドキュメントは保存後に変更も削除もできないようにする必要がある場合に正しいS3の設定は？**]<br>\n",
    "- S3オブジェクトロックのコンプライアンスモードを有効にしたS3バケットを作成して、その中にドキュメントを保存する。\n",
    "- (補足) ・Amazon S3バケットにMFA Delete機能を適用して、ユーザーによるデータ削除時にMFA入力を必須化して、誤った削除を防止する。<br>\n",
    "  ・Amazon S3バケットの初期設定でデータが削除されないS3バケットをロックする。\n",
    "といった処理も考えられる\n",
    "- (注意点)　S3オブジェクトロックの**ガバナンスモードはルートユーザーなどの一部管理者はデータの削除を実行することが可能**\n",
    "\n",
    "\n",
    "[**Route53のDNSレコードにCloudFrontを設定してドメインを関連付ける方法は？**]<br>\n",
    "- ALIASレコードを作成してCloudFrontを構成することで、Route53のDNSレコードにCloudFrontを設定してドメインを関連付けることができます。その際に、IPv4に基づいたドメイン設定をする場合は、Aレコードタイプにすることが必要です。Route53のコンソール画面で、レコードを作成において[エイリアス] をオンにしてレコードタイプはAにして、CloudFrontディストリビューションのドメインを指定することで設定ができます。\n",
    "- (補足)CNAMEレコードとは？\n",
    "  - CNAMEレコードは特定のドメインに対して別のドメインを設定して、ドメイン間の名前解決を設定する際に利用します。Aレコードが「ホスト名とIPv4アドレスの関連付けを定義するレコード」\n",
    "  - AWS CloudFront でコンテンツを配信する場合、\n",
    "CloudFront のエンドポイントは d123456abcdef.cloudfront.net のような長い URL になります。でも、こんな長い URL を使うのは不便なので、カスタムドメイン（例: cdn.example.com）でアクセスできるようにする ために CNAME を設定します。\n",
    "\n",
    "\n",
    "[**Amazon SQSキューからメッセージを取得するコンシューマーがメッセージ処理に失敗すると、他のコンシューマーがメッセージを処理するまでに5分以上のタイムラグが発生、どうす？？**]<br>\n",
    "- これは5分以上の可視性タイムアウトが設定されていることが理由です。<br>\n",
    "SQSキューのメッセージがコンシューマーに受信された直後は、メッセージはキューに残ったままとなっています。したがって、他のコンシューマーが同じメッセージを再処理しないように、Amazon SQS は可視性タイムアウトを設定することが必要です。\n",
    "\n",
    "この可視性タイムアウト時間内では、他のコンシューマーが同じメッセージを受信して処理することはできません。デフォルトの可視性タイムアウトは 30 秒に設定されており、最小値は 0 秒、最大スケールは 12 時間に設定が可能です。コンシューマの1つがメッセージを受信すると、その特定のメッセージの可視性タイムアウトが期限切れになるまで、他のコンシューマーはメッセージを再度読み取ることはできません。したがって、可視性タイムアウトの設定時間を減少させることで、他のコンシューマーがメッセージを処理するための待ち時間を短縮することができます。\n",
    "\n",
    "\n",
    "[**EC2インスタンスには同じAWSリージョン内にある複数のAmazon S3バケット間で、画像を共有する仕組みが必要です。画像をアップロードしたり、ダウンロードが繰り返されるため、データ転送コストが増加してしまいました。どうコスト削減する？**]<br>\n",
    "- インターフェースエンドポイントをVPC内のプライベートサブネットに配置する。そこに、Amazon S3バケットへのアクセスを許可するエンドポイントポリシーをアタッチする。\n",
    "- ゲートウェイエンドポイントをVPCに配置する。そこに、Amazon S3バケットへのアクセスを許可するエンドポイントポリシーをアタッチする。\n",
    "- （補足）VPCからAmazon S3 へのアクセスには、ゲートウェイエンドポイントとインターフェイスエンドポイント (AWS PrivateLink を使用) の 2 つのタイプの VPC エンドポイントを使用できます。\n",
    "- （補足）ゲートウェイエンドポイントはAWS ネットワーク経由で VPC から Amazon S3 にアクセスするためにVPCのルートテーブルにおいてルート指定が必要なゲートウェイです。ゲートウェイエンドポイントは、VPC にインターネットゲートウェイや NAT デバイスを通さずに、Amazon S3 および DynamoDB への信頼性の高い接続を提供.S3 や DynamoDB へ接続したいリソースが配置されている VPC に VPC エンドポイントを割り当て、ルートテーブルに ターゲットが VPC エンドポイントのルーティング を設定します。\n",
    "- インターフェースエンドポイントはプライベート IP アドレスを使用してVPC から Amazon S3 にリクエストをルーティングすることができるインターフェースタイプのエンドポイントです。ゲートウェイではないため、プライベート IP アドレスを利用した制御を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d043c47-e3de-4326-896a-61d80cefcc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
