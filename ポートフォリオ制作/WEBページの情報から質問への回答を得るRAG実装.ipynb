{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.25.1"
      ],
      "metadata": {
        "id": "N0YMUAIAv_IN",
        "outputId": "4189bd28-b0a2-4115-84b2-e5e417869a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N0YMUAIAv_IN",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.25.1\n",
            "  Downloading openai-1.25.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.1) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.25.1) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.25.1) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.25.1) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.25.1) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.25.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.25.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.25.1) (2.27.1)\n",
            "Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpx==0.27.2"
      ],
      "metadata": {
        "id": "S5mRt1FOwDcj",
        "outputId": "5e6075f7-34aa-4503-8199-0ca92c120add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S5mRt1FOwDcj",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.2) (1.2.2)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpx-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup #ウェブスクレイピングでHTMLデータを解析し、データ抽出\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPEN_API_KEY\"] = userdata.get('OPEN_API_KEY')\n",
        "# OpenAIクライアントを初期化\n",
        "client = OpenAI(api_key= os.environ[\"OPEN_API_KEY\"])\n",
        "\n",
        "# 先ほど作成したスクレイピング処理の関数化\n",
        "def scrape_article(url):\n",
        "# 対象のURLを取得（スクレイピング処理）\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\") #対象urlのhtmlを取得\n",
        "  print(soup)\n",
        "\n",
        "  # テキストの情報だけを取得してくる\n",
        "  text_nodes = soup.find_all(\"div\")\n",
        "  len(text_nodes) #divで囲まれてる箇所何か所あるか確認\n",
        "  for t in text_nodes:\n",
        "    print(t.text) #t.textでtext属性のものだけを取得できる\n",
        "\n",
        "  # 上記テキスト情報をリストへ格納\n",
        "  t_all = []\n",
        "  for t in text_nodes:\n",
        "    t_all.append(t.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\")) #\\n,\\tを\"\"に変換\"\n",
        "    print(t_all)\n",
        "\n",
        "  #文字列をまずはすべて結合させる\n",
        "  joined_text =  \"\".join(t_all)\n",
        "  return joined_text\n",
        "\n",
        "\n",
        "# chunkの取得処理も関数化\n",
        "# 400文字で一区切り、50文字戻り350+50で区切っていく\n",
        "def chunk_text(text,chunk_size,overlap,):\n",
        "  chunks = []\n",
        "  start = 0\n",
        "\n",
        "  while start + chunk_size <= len(text): #この文字数までは回し続ける\n",
        "    chunks.append(text[start:start + chunk_size]) #最初は0:400文字まではいってる\n",
        "    start += (chunk_size - overlap)\n",
        "  #上記処理では最後が例えばstart:1100だと残り分を残したまま処理が終わってしまうため残り分を算出\n",
        "  if start < len(text):\n",
        "    chunks.append(text[-chunk_size:])\n",
        "\n",
        "  return chunks\n",
        "\n",
        "# テキストをベクトル化する関数処理流用\n",
        "  #client.embeddingsでembeddingsAPIをcallする\n",
        "def vectorize_text(text):\n",
        "  response = client.embeddings.create(\n",
        "      input = text,\n",
        "      model = \"text-embedding-3-small\"\n",
        "  )\n",
        "  return response.data[0].embedding\n",
        "\n",
        "# documentsの中で最も高い類似度を格納する処理も関数化\n",
        "def find_most_similar(question_vector, vectors, documents):\n",
        "  max_similarity = 0\n",
        "  most_similar_index = 0\n",
        "\n",
        "  for index, vector in enumerate(vectors):\n",
        "    similarity = cosine_similarity([question_vector], [vector])[0][0]\n",
        "    print(documents[index], \":\", similarity) #処理の流れ確認\n",
        "    if similarity > max_similarity:\n",
        "      max_similarity = similarity\n",
        "      most_similar_index = index\n",
        "\n",
        "  return documents[most_similar_index]\n",
        "\n",
        "# 質問への回答を出力するプロンプトも関数化\n",
        "def ask_question(question_context, context):\n",
        "  prompt = f''' 以下の質問に以下情報から答えてください。\n",
        "  [ユーザへの質問]\n",
        "  {question}\n",
        "\n",
        "  [情報]\n",
        "  {documents[most_similar_index]}\n",
        "  '''\n",
        "  print(prompt)\n",
        "  response = client.completions.create(\n",
        "      model = \"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt,\n",
        "      max_tokens = 200\n",
        "  )\n",
        "\n",
        "  return response.choices[0].text\n"
      ],
      "metadata": {
        "id": "N1w63ttNtbOM",
        "outputId": "73de78bc-3ba0-4978-8ad8-4dc790de74cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "id": "N1w63ttNtbOM",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8c89d477826c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPEN_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPEN_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# OpenAIクライアントを初期化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPEN_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 先ほど作成したスクレイピング処理の関数化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         super().__init__(\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mexc_tb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTracebackType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     ) -> None:\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     def _prepare_options(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_MAX_RETRIES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0mtransport\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTransport\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実際にWEBページの情報をもとに回答プロンプトを実装"
      ],
      "metadata": {
        "id": "OmmyaW-7tdFz"
      },
      "id": "OmmyaW-7tdFz"
    },
    {
      "cell_type": "code",
      "source": [
        "# 引数\n",
        "url = \"https://toukei-lab.com/achademy/?page_id=1619\"\n",
        "chunk_size = 400\n",
        "overlap = 50\n",
        "\n",
        "\n",
        "# 実際に作成した関数にて挙動の確認\n",
        "article_text = scrape_article(url)\n",
        "text_chunks = chunk_text(article_text, chunk_size, overlap) #chunksの中にurlの文字列を格納\n",
        "\n",
        "# documents(text_chunks)とquestionに分けていく作業\n",
        "# chunksのchunkを一つ一つ取り出し、ベクトル化処理に入れ込む\n",
        "vectors = [vectorize_text(doc) for doc in text_chunks]\n",
        "\n",
        "question = \"オーダーメイドプランの価格はいくら？\"\n",
        "question_vector = vectorize_text(question)\n",
        "\n",
        "# documentsの中から最も高い類似度のもの(答え)を格納\n",
        "similar_document = find_most_similar(question_vector, vectors,text_chunks)\n",
        "\n",
        "# 質問への回答を出力するプロンプトにて\n",
        "answer = ask_question(question, similar_document)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "C-ESvdyGtiMR"
      },
      "id": "C-ESvdyGtiMR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}